"""
RamanSPy GUI - Giao di·ªán ƒë·ªì h·ªça cho ph√¢n t√≠ch ph·ªï Raman
Ch·∫°y ·ª©ng d·ª•ng: streamlit run ramanspy_gui.py
"""

import streamlit as st
import ramanspy as rp
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import tempfile
import os
import io
import pandas as pd

# Helper functions
def plot_with_download(fig, filename="plot.png", download_label="üì• T·∫£i plot"):
    """Display plot with download button"""
    # Save to bytes
    buf = io.BytesIO()
    fig.savefig(buf, format='png', dpi=300, bbox_inches='tight')
    buf.seek(0)

    # Display plot
    st.pyplot(fig)

    # Download button
    st.download_button(
        label=download_label,
        data=buf,
        file_name=filename,
        mime="image/png",
        use_container_width=True
    )

    plt.close(fig)

def create_csv_download(dataframe, filename="data.csv", label="üì• T·∫£i CSV"):
    """Create download button for CSV data"""
    csv_buffer = io.StringIO()
    dataframe.to_csv(csv_buffer, index=False, encoding='utf-8')
    csv_buffer.seek(0)

    st.download_button(
        label=label,
        data=csv_buffer.getvalue(),
        file_name=filename,
        mime="text/csv",
        use_container_width=True
    )

# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="RamanSPy GUI",
    page_icon="üî¨",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS t√πy ch·ªânh
st.markdown("""
    <style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.5rem;
        font-weight: bold;
        color: #2ca02c;
        margin-top: 2rem;
        margin-bottom: 1rem;
    }
    </style>
""", unsafe_allow_html=True)

# Header
st.markdown('<p class="main-header">üî¨ RamanSPy - Ph√¢n t√≠ch ph·ªï Raman</p>', unsafe_allow_html=True)

# Kh·ªüi t·∫°o session state
if 'data' not in st.session_state:
    st.session_state.data = None
if 'preprocessed_data' not in st.session_state:
    st.session_state.preprocessed_data = None
if 'pipeline_steps' not in st.session_state:
    st.session_state.pipeline_steps = []
if 'analysis_results' not in st.session_state:
    st.session_state.analysis_results = None
if 'spectra_collection' not in st.session_state:
    st.session_state.spectra_collection = []  # List of {'name': str, 'data': Spectrum, 'preprocessed': None}
if 'processed_file_ids' not in st.session_state:
    st.session_state.processed_file_ids = set()  # Track which files have been added to avoid duplicates

# Sidebar - Navigation
st.sidebar.title("üìã Menu")
page = st.sidebar.radio(
    "Ch·ªçn ch·ª©c nƒÉng:",
    ["T·∫£i d·ªØ li·ªáu", "Ti·ªÅn x·ª≠ l√Ω", "Ph√¢n t√≠ch", "Tr·ª±c quan h√≥a"]
)

st.sidebar.markdown("---")
st.sidebar.info("""
**RamanSPy GUI v1.0**

C√¥ng c·ª• ph√¢n t√≠ch ph·ªï Raman ƒë∆°n gi·∫£n v√† d·ªÖ s·ª≠ d·ª•ng.

[T√†i li·ªáu](https://ramanspy.readthedocs.io)
""")

# ==================== TRANG T·∫¢I D·ªÆ LI·ªÜU ====================
if page == "T·∫£i d·ªØ li·ªáu":
    st.markdown('<p class="sub-header">üìÇ T·∫£i d·ªØ li·ªáu ph·ªï Raman</p>', unsafe_allow_html=True)

    tab1, tab2, tab3 = st.tabs(["üìÅ T·∫£i t·ª´ file", "üìä D·ªØ li·ªáu m·∫´u", "üé≤ D·ªØ li·ªáu t·ªïng h·ª£p"])

    # Tab 1: T·∫£i t·ª´ file
    with tab1:
        st.write("### T·∫£i d·ªØ li·ªáu t·ª´ file")

        col1, col2 = st.columns([2, 1])

        with col1:
            file_format = st.selectbox(
                "Ch·ªçn ƒë·ªãnh d·∫°ng file:",
                ["CSV/Text (t√πy ch·ªânh)", "WITec", "Renishaw", "NumPy (.npy)"]
            )

        with col2:
            st.info("üí° Ch·ªçn ƒë√∫ng ƒë·ªãnh d·∫°ng c·ªßa thi·∫øt b·ªã ƒëo")

        # H∆∞·ªõng d·∫´n cho CSV/Text
        if file_format == "CSV/Text (t√πy ch·ªânh)":
            with st.expander("‚ÑπÔ∏è ƒê·ªãnh d·∫°ng CSV/Text ƒë∆∞·ª£c h·ªó tr·ª£"):
                st.write("""
                **ƒê·ªãnh d·∫°ng file ƒë∆∞·ª£c h·ªó tr·ª£:**
                - Header (t√πy ch·ªçn) v·ªõi metadata
                - D·ªØ li·ªáu 2 c·ªôt: Wavenumber v√† Intensity
                - Ph√¢n c√°ch b·∫±ng: `;` , `,` , tab ho·∫∑c kho·∫£ng tr·∫Øng

                **V√≠ d·ª•:**
                ```
                Name=Andor Spectra
                X=Raman Shift, 1/cm
                Y=Intensity, Counts
                2.37; 2405
                6.04; 2446
                9.70; 2369
                ...
                ```
                """)

        uploaded_files = st.file_uploader(
            "Ch·ªçn file d·ªØ li·ªáu:",
            type=['txt', 'csv', 'wdf', 'npy', 'npz', 'dat'],
            help="H·ªó tr·ª£ nhi·ªÅu ƒë·ªãnh d·∫°ng file t·ª´ c√°c thi·∫øt b·ªã Raman kh√°c nhau",
            accept_multiple_files=True
        )

        # Checkbox ƒë·ªÉ t·ª± ƒë·ªông th√™m v√†o collection
        st.markdown("---")
        auto_add_to_collection = st.checkbox(
            "‚úÖ T·ª± ƒë·ªông th√™m T·∫§T C·∫¢ v√†o Collection sau khi t·∫£i",
            value=True,
            help="Khuy·∫øn ngh·ªã B·∫¨T option n√†y ƒë·ªÉ t·∫•t c·∫£ files ƒë∆∞·ª£c th√™m v√†o Collection t·ª± ƒë·ªông"
        )
        if auto_add_to_collection:
            st.caption("üí° T·∫•t c·∫£ files upload s·∫Ω t·ª± ƒë·ªông ƒë∆∞·ª£c th√™m v√†o Collection ƒë·ªÉ qu·∫£n l√Ω v√† x·ª≠ l√Ω h√†ng lo·∫°t")
        else:
            st.caption("‚ö†Ô∏è Files s·∫Ω KH√îNG ƒë∆∞·ª£c th√™m v√†o Collection - b·∫°n ph·∫£i th√™m th·ªß c√¥ng")

        # Hi·ªÉn th·ªã s·ªë files ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω
        if len(st.session_state.processed_file_ids) > 0:
            st.info(f"üìä ƒê√£ x·ª≠ l√Ω {len(st.session_state.processed_file_ids)} file(s) trong session n√†y. M·ªói file ch·ªâ ƒë∆∞·ª£c th√™m v√†o Collection 1 l·∫ßn duy nh·∫•t.")

        if uploaded_files:
            loaded_count = 0
            failed_files = []

            for uploaded_file in uploaded_files:
                # T·∫°o unique ID cho file (d·ª±a tr√™n t√™n file + k√≠ch th∆∞·ªõc + file_id n·∫øu c√≥)
                file_id = f"{uploaded_file.name}_{uploaded_file.size}"
                if hasattr(uploaded_file, 'file_id'):
                    file_id = f"{uploaded_file.file_id}_{uploaded_file.name}_{uploaded_file.size}"

                # Ki·ªÉm tra xem file ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω ch∆∞a
                if file_id in st.session_state.processed_file_ids:
                    continue  # Skip file n√†y v√¨ ƒë√£ x·ª≠ l√Ω r·ªìi

                try:
                    # L∆∞u file t·∫°m
                    with tempfile.NamedTemporaryFile(delete=False, suffix=Path(uploaded_file.name).suffix) as tmp_file:
                        tmp_file.write(uploaded_file.getvalue())
                        tmp_path = tmp_file.name

                    with st.spinner(f"ƒêang t·∫£i {uploaded_file.name}..."):
                        # Load d·ªØ li·ªáu theo ƒë·ªãnh d·∫°ng
                        if file_format == "WITec":
                            loaded_data = rp.load.witec(tmp_path)
                        elif file_format == "Renishaw":
                            loaded_data = rp.load.renishaw(tmp_path)
                        elif file_format == "NumPy (.npy)":
                            data_array = np.load(tmp_path)
                            loaded_data = rp.Spectrum(data_array)
                        else:
                            # CSV/Text (t√πy ch·ªânh)
                            with open(tmp_path, 'r', encoding='utf-8') as f:
                                lines = f.readlines()

                            # T√¨m d√≤ng b·∫Øt ƒë·∫ßu d·ªØ li·ªáu
                            data_start = 0
                            for i, line in enumerate(lines):
                                if line.strip() and (line.strip()[0].isdigit() or line.strip()[0] == '-'):
                                    data_start = i
                                    break

                            # Parse d·ªØ li·ªáu
                            wavenumbers = []
                            intensities = []

                            for line in lines[data_start:]:
                                line = line.strip()
                                if not line:
                                    continue

                                # Th·ª≠ c√°c delimiter kh√°c nhau
                                if ';' in line:
                                    parts = line.split(';')
                                elif ',' in line:
                                    parts = line.split(',')
                                elif '\t' in line:
                                    parts = line.split('\t')
                                else:
                                    parts = line.split()

                                if len(parts) >= 2:
                                    try:
                                        wavenumbers.append(float(parts[0].strip()))
                                        intensities.append(float(parts[1].strip()))
                                    except ValueError:
                                        continue

                            # T·∫°o Spectrum object
                            if len(wavenumbers) > 0 and len(intensities) > 0:
                                loaded_data = rp.Spectrum(
                                    np.array(intensities),
                                    spectral_axis=np.array(wavenumbers)
                                )
                            else:
                                raise ValueError("Kh√¥ng th·ªÉ ƒë·ªçc d·ªØ li·ªáu t·ª´ file.")

                    os.unlink(tmp_path)

                    # L∆∞u v√†o st.session_state.data (file cu·ªëi c√πng)
                    st.session_state.data = loaded_data

                    # T·ª± ƒë·ªông th√™m v√†o collection n·∫øu ƒë∆∞·ª£c ch·ªçn
                    if auto_add_to_collection:
                        # L·∫•y t√™n file (kh√¥ng c√≥ extension)
                        file_base_name = Path(uploaded_file.name).stem

                        # Ki·ªÉm tra tr√πng t√™n
                        existing_names = [s['name'] for s in st.session_state.spectra_collection]
                        final_name = file_base_name
                        counter = 1
                        while final_name in existing_names:
                            final_name = f"{file_base_name}_{counter}"
                            counter += 1

                        st.session_state.spectra_collection.append({
                            'name': final_name,
                            'original_filename': uploaded_file.name,
                            'data': loaded_data,
                            'preprocessed': None,
                            'selected': True
                        })

                    # ƒê√°nh d·∫•u file n√†y ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω
                    st.session_state.processed_file_ids.add(file_id)

                    loaded_count += 1

                except Exception as e:
                    failed_files.append((uploaded_file.name, str(e)))

            # Hi·ªÉn th·ªã k·∫øt qu·∫£
            if loaded_count > 0:
                st.success(f"‚úÖ ƒê√£ t·∫£i th√†nh c√¥ng {loaded_count} file(s)")
                if auto_add_to_collection:
                    st.info(f"üí° ƒê√£ th√™m {loaded_count} ph·ªï v√†o Collection. M·ªü r·ªông 'üìö Qu·∫£n l√Ω Collection Ph·ªï' ƒë·ªÉ xem.")

            if failed_files:
                st.error(f"‚ùå L·ªói khi t·∫£i {len(failed_files)} file(s):")
                for fname, error in failed_files:
                    st.write(f"- {fname}: {error}")

            # Hi·ªÉn th·ªã th√¥ng tin ph·ªï cu·ªëi c√πng ƒë∆∞·ª£c load
            if st.session_state.data is not None and loaded_count > 0:
                st.write("### Th√¥ng tin ph·ªï cu·ªëi c√πng ƒë∆∞·ª£c t·∫£i")
                col1, col2, col3 = st.columns(3)

                with col1:
                    st.metric("Ki·ªÉu d·ªØ li·ªáu", type(st.session_state.data).__name__)
                with col2:
                    st.metric("K√≠ch th∆∞·ªõc", str(st.session_state.data.shape))
                with col3:
                    if hasattr(st.session_state.data, 'spectral_axis'):
                        st.metric("S·ªë ƒëi·ªÉm ph·ªï", len(st.session_state.data.spectral_axis))

    # Tab 2: D·ªØ li·ªáu m·∫´u
    with tab2:
        st.write("### T·∫£i d·ªØ li·ªáu m·∫´u t·ª´ RamanSPy")

        st.info("üì• D·ªØ li·ªáu s·∫Ω ƒë∆∞·ª£c t·∫£i xu·ªëng t·ª± ƒë·ªông t·ª´ repository")

        dataset_type = st.selectbox(
            "Ch·ªçn lo·∫°i d·ªØ li·ªáu:",
            ["THP-1 cells", "MCF-7 cells", "Bacteria dataset"]
        )

        col1, col2 = st.columns([1, 3])

        with col1:
            if st.button("üì• T·∫£i d·ªØ li·ªáu m·∫´u", type="primary"):
                try:
                    with st.spinner("ƒêang t·∫£i d·ªØ li·ªáu m·∫´u..."):
                        data_dir = "./data/kallepitis_data"

                        # Ch·ªçn cell type
                        if dataset_type == "THP-1 cells":
                            cell_type = 'THP-1'
                        elif dataset_type == "MCF-7 cells":
                            cell_type = 'MCF-7'
                        else:
                            cell_type = 'THP-1'

                        volumes = rp.datasets.volumetric_cells(cell_type=cell_type, folder=data_dir)
                        st.session_state.data = volumes[0]

                        st.success(f"‚úÖ ƒê√£ t·∫£i d·ªØ li·ªáu m·∫´u: {dataset_type}")
                        st.rerun()

                except Exception as e:
                    st.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ t·∫£i d·ªØ li·ªáu m·∫´u: {str(e)}")
                    st.info("D·ªØ li·ªáu m·∫´u c·∫ßn ƒë∆∞·ª£c t·∫£i v·ªÅ tr∆∞·ªõc. B·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng d·ªØ li·ªáu t·ªïng h·ª£p ƒë·ªÉ th·ª≠ nghi·ªám.")

        with col2:
            if dataset_type == "THP-1 cells":
                st.write("**THP-1 cells**: D·ªØ li·ªáu ph·ªï Raman 3D c·ªßa t·∫ø b√†o THP-1")
            elif dataset_type == "MCF-7 cells":
                st.write("**MCF-7 cells**: D·ªØ li·ªáu ph·ªï Raman 3D c·ªßa t·∫ø b√†o MCF-7")

    # Tab 3: D·ªØ li·ªáu t·ªïng h·ª£p
    with tab3:
        st.write("### T·∫°o d·ªØ li·ªáu t·ªïng h·ª£p ƒë·ªÉ th·ª≠ nghi·ªám")

        col1, col2 = st.columns(2)

        with col1:
            n_spectra = st.slider("S·ªë ph·ªï:", 10, 1000, 100)
            n_points = st.slider("S·ªë ƒëi·ªÉm ph·ªï:", 100, 2000, 500)

        with col2:
            noise_level = st.slider("M·ª©c nhi·ªÖu:", 0.0, 0.5, 0.1, 0.05)
            n_peaks = st.slider("S·ªë peak:", 1, 10, 3)

        if st.button("üé≤ T·∫°o d·ªØ li·ªáu t·ªïng h·ª£p", type="primary"):
            with st.spinner("ƒêang t·∫°o d·ªØ li·ªáu..."):
                # T·∫°o tr·ª•c wavenumber
                wavenumbers = np.linspace(400, 2000, n_points)

                # T·∫°o ph·ªï v·ªõi nhi·ªÅu peaks
                spectra_list = []
                for _ in range(n_spectra):
                    spectrum = np.zeros(n_points)

                    # Th√™m peaks ng·∫´u nhi√™n
                    for _ in range(n_peaks):
                        center = np.random.uniform(600, 1800)
                        width = np.random.uniform(20, 80)
                        height = np.random.uniform(0.5, 1.0)

                        # Gaussian peak
                        spectrum += height * np.exp(-((wavenumbers - center) ** 2) / (2 * width ** 2))

                    # Th√™m baseline
                    baseline = np.random.uniform(0.1, 0.3) * np.ones(n_points)
                    spectrum += baseline

                    # Th√™m nhi·ªÖu
                    noise = np.random.normal(0, noise_level, n_points)
                    spectrum += noise

                    spectra_list.append(spectrum)

                # T·∫°o SpectralContainer
                data_array = np.array(spectra_list)
                st.session_state.data = rp.SpectralContainer(data_array, spectral_axis=wavenumbers)

                st.success(f"‚úÖ ƒê√£ t·∫°o {n_spectra} ph·ªï t·ªïng h·ª£p v·ªõi {n_points} ƒëi·ªÉm")

    # ==================== QU·∫¢N L√ù NHI·ªÄU PH·ªî ====================
    st.markdown("---")
    with st.expander("üìö Qu·∫£n l√Ω Collection Ph·ªï (ƒë·ªÉ ch·∫°y PCA v·ªõi nhi·ªÅu ph·ªï)", expanded=False):
        st.write("### Th√™m ph·ªï hi·ªán t·∫°i v√†o collection")

        col_name, col_add = st.columns([3, 1])

        with col_name:
            spectrum_name = st.text_input(
                "T√™n ph·ªï:",
                value=f"Spectrum_{len(st.session_state.spectra_collection)+1}",
                help="ƒê·∫∑t t√™n ƒë·ªÉ d·ªÖ qu·∫£n l√Ω"
            )

        with col_add:
            st.write("")  # Spacing
            st.write("")  # Spacing
            if st.button("‚ûï Th√™m v√†o Collection"):
                if st.session_state.data is not None:
                    # Ki·ªÉm tra tr√πng t√™n
                    existing_names = [s['name'] for s in st.session_state.spectra_collection]
                    if spectrum_name in existing_names:
                        st.error(f"‚ùå T√™n '{spectrum_name}' ƒë√£ t·ªìn t·∫°i!")
                    else:
                        st.session_state.spectra_collection.append({
                            'name': spectrum_name,
                            'data': st.session_state.data,
                            'preprocessed': st.session_state.preprocessed_data,
                            'selected': True
                        })
                        st.success(f"‚úÖ ƒê√£ th√™m '{spectrum_name}' v√†o collection!")
                        st.rerun()
                else:
                    st.warning("‚ö†Ô∏è Ch∆∞a c√≥ d·ªØ li·ªáu ƒë·ªÉ th√™m. Vui l√≤ng t·∫£i file tr∆∞·ªõc!")

        # Hi·ªÉn th·ªã collection
        if len(st.session_state.spectra_collection) > 0:
            # Th·ªëng k√™ collection
            total_count = len(st.session_state.spectra_collection)
            preprocessed_count = sum(1 for s in st.session_state.spectra_collection if s['preprocessed'] is not None)

            st.write(f"### üìã Collection ({total_count} ph·ªï)")

            # Progress bar cho preprocessing status
            if total_count > 0:
                progress = preprocessed_count / total_count
                st.progress(progress, text=f"ƒê√£ ti·ªÅn x·ª≠ l√Ω: {preprocessed_count}/{total_count} ph·ªï ({progress*100:.0f}%)")

            st.markdown("")  # Spacing

            # Selection mode
            col_mode1, col_mode2, col_mode3, col_mode4 = st.columns(4)
            with col_mode1:
                if st.button("‚úÖ Ch·ªçn t·∫•t c·∫£"):
                    for spec in st.session_state.spectra_collection:
                        spec['selected'] = True
                    st.rerun()
            with col_mode2:
                if st.button("‚òê B·ªè ch·ªçn t·∫•t c·∫£"):
                    for spec in st.session_state.spectra_collection:
                        spec['selected'] = False
                    st.rerun()
            with col_mode3:
                if st.button("üóëÔ∏è X√≥a t·∫•t c·∫£"):
                    st.session_state.spectra_collection = []
                    st.session_state.processed_file_ids = set()
                    st.rerun()
            with col_mode4:
                if st.button("üîÑ Reset cache"):
                    st.session_state.processed_file_ids = set()
                    st.info("ƒê√£ x√≥a cache upload")
                    st.rerun()

            # List spectra v·ªõi rename
            for i, spec in enumerate(st.session_state.spectra_collection):
                col1, col2, col3, col4, col5 = st.columns([0.5, 2, 2, 0.6, 0.6])

                with col1:
                    new_selected = st.checkbox(
                        "‚òë",
                        value=spec['selected'],
                        key=f"select_{i}",
                        label_visibility="collapsed"
                    )
                    if new_selected != spec['selected']:
                        spec['selected'] = new_selected

                with col2:
                    # Hi·ªÉn th·ªã t√™n file g·ªëc n·∫øu c√≥
                    original_name = spec.get('original_filename', '')
                    if original_name:
                        st.write(f"üìÑ `{original_name}`")
                    else:
                        st.write(f"Ph·ªï #{i+1}")

                with col3:
                    # Editable name
                    new_name = st.text_input(
                        "T√™n:",
                        value=spec['name'],
                        key=f"name_{i}",
                        label_visibility="collapsed",
                        placeholder="ƒê·∫∑t t√™n..."
                    )
                    if new_name != spec['name'] and new_name.strip():
                        # Check duplicate
                        existing = [s['name'] for idx, s in enumerate(st.session_state.spectra_collection) if idx != i]
                        if new_name not in existing:
                            spec['name'] = new_name

                    # Status v·ªõi m√†u s·∫Øc r√µ r√†ng
                    data_shape = spec['data'].shape if hasattr(spec['data'], 'shape') else "N/A"
                    if spec['preprocessed'] is not None:
                        st.caption(f"‚úÖ **ƒê√£ x·ª≠ l√Ω** | {data_shape}")
                    else:
                        st.caption(f"‚ö™ *Ch∆∞a x·ª≠ l√Ω* | {data_shape}")

                with col4:
                    if st.button("üóëÔ∏è", key=f"del_{i}", help="X√≥a"):
                        st.session_state.spectra_collection.pop(i)
                        st.rerun()

                with col5:
                    if st.button("üëÅÔ∏è", key=f"view_{i}", help="Load"):
                        st.session_state.data = spec['data']
                        st.session_state.preprocessed_data = spec['preprocessed']
                        st.success(f"ƒê√£ load '{spec['name']}'")
                        st.rerun()

            # Actions
            st.markdown("---")
            selected_count = sum(1 for s in st.session_state.spectra_collection if s['selected'])

            # Hi·ªÉn th·ªã th·ªëng k√™ chi ti·∫øt
            col_stat1, col_stat2, col_stat3 = st.columns(3)
            with col_stat1:
                st.metric("ƒê√£ ch·ªçn", f"{selected_count}/{total_count}")
            with col_stat2:
                selected_preprocessed = sum(1 for s in st.session_state.spectra_collection if s['selected'] and s['preprocessed'] is not None)
                st.metric("ƒê√£ x·ª≠ l√Ω", f"{selected_preprocessed}/{selected_count}")
            with col_stat3:
                selected_raw = selected_count - selected_preprocessed
                if selected_raw > 0:
                    st.metric("Ch∆∞a x·ª≠ l√Ω", selected_raw, delta="C·∫ßn x·ª≠ l√Ω", delta_color="off")
                else:
                    st.metric("Ch∆∞a x·ª≠ l√Ω", "0", delta="‚úì", delta_color="normal")

            st.markdown("")

            if selected_count > 0:
                # Batch preprocessing section
                st.write("#### ‚öôÔ∏è Ti·ªÅn x·ª≠ l√Ω h√†ng lo·∫°t")
                st.info("üí° Chuy·ªÉn sang tab **'Ti·ªÅn x·ª≠ l√Ω'** ƒë·ªÉ:")
                st.markdown("""
                1. Thi·∫øt l·∫≠p pipeline ti·ªÅn x·ª≠ l√Ω
                2. Click **'‚öôÔ∏è √Åp d·ª•ng cho Collection'** ƒë·ªÉ x·ª≠ l√Ω h√†ng lo·∫°t
                3. Click **'üîó K·∫øt h·ª£p ph·ªï'** ƒë·ªÉ t·∫°o SpectralContainer cho PCA
                """)

                col_quick = st.columns(1)[0]
                with col_quick:
                    # Quick access button
                    if st.button("üìç ƒêi t·ªõi Ti·ªÅn x·ª≠ l√Ω", use_container_width=True, type="primary"):
                        st.session_state['show_batch_hint'] = True
                        st.info("Chuy·ªÉn sang tab 'Ti·ªÅn x·ª≠ l√Ω' b√™n tr√™n!")

            elif selected_count == 1:
                st.info("üí° Ch·ªâ ch·ªçn 1 ph·ªï. S·ª≠ d·ª•ng Peak Detection ƒë·ªÉ ph√¢n t√≠ch ph·ªï ƒë∆°n.")
        else:
            st.info("Collection tr·ªëng. T·∫£i file v√† ch·ªçn 'T·ª± ƒë·ªông th√™m v√†o Collection' khi upload.")

    # Preview d·ªØ li·ªáu n·∫øu ƒë√£ load
    if st.session_state.data is not None:
        st.markdown("---")
        st.write("### üëÄ Preview d·ªØ li·ªáu")

        try:
            # L·∫•y m·ªôt v√†i ph·ªï ƒë·ªÉ hi·ªÉn th·ªã
            data_type = type(st.session_state.data).__name__

            if data_type == 'Spectrum':
                # Spectrum ƒë∆°n l·∫ª - plot v·ªõi m√†u ƒë·∫πp
                fig, ax = plt.subplots(figsize=(10, 4), dpi=150)

                if hasattr(st.session_state.data, 'spectral_axis') and hasattr(st.session_state.data, 'spectral_data'):
                    ax.plot(st.session_state.data.spectral_axis, st.session_state.data.spectral_data,
                           color='#1f77b4', linewidth=1.5)
                    ax.set_xlabel("Wavenumber (cm‚Åª¬π)")
                    ax.set_ylabel("Intensity")
                else:
                    rp.plot.spectra(st.session_state.data, ax=ax, plot_type='single')

                ax.set_title("Preview ph·ªï Raman")
                ax.grid(True, alpha=0.3)
                st.pyplot(fig)
                plt.close()

            elif data_type == 'SpectralContainer' or (hasattr(st.session_state.data, 'spectral_data') and hasattr(st.session_state.data.spectral_data, 'shape') and len(st.session_state.data.spectral_data.shape) > 1):
                # SpectralContainer ho·∫∑c multi-spectrum data
                if hasattr(st.session_state.data, 'spectral_data'):
                    n_spectra = min(5, len(st.session_state.data.spectral_data))
                else:
                    n_spectra = min(5, len(st.session_state.data))

                # L·∫•y t√™n t·ª´ Collection n·∫øu c√≥
                spectrum_labels = []
                if len(st.session_state.spectra_collection) > 0:
                    selected_items = [s for s in st.session_state.spectra_collection if s['selected']]
                    if len(selected_items) > 0:
                        spectrum_labels = [item['name'] for item in selected_items[:n_spectra]]

                # Fallback labels n·∫øu kh√¥ng c√≥ t·ª´ collection
                if len(spectrum_labels) == 0:
                    spectrum_labels = [f'Ph·ªï {i+1}' for i in range(n_spectra)]

                colors = plt.cm.tab10(np.linspace(0, 1, n_spectra))

                fig, ax = plt.subplots(figsize=(10, 4), dpi=150)
                for i in range(n_spectra):
                    # Get spectrum
                    if hasattr(st.session_state.data, 'spectral_data'):
                        y_data = st.session_state.data.spectral_data[i]
                        x_data = st.session_state.data.spectral_axis if hasattr(st.session_state.data, 'spectral_axis') else np.arange(len(y_data))
                    else:
                        spec = st.session_state.data[i]
                        if hasattr(spec, 'spectral_axis') and hasattr(spec, 'spectral_data'):
                            x_data = spec.spectral_axis
                            y_data = spec.spectral_data
                        else:
                            y_data = spec if isinstance(spec, np.ndarray) else np.array(spec)
                            x_data = np.arange(len(y_data))

                    # Flatten if needed
                    if hasattr(y_data, 'shape') and len(y_data.shape) > 1:
                        y_data = y_data.flatten()

                    # Use name from collection
                    label = spectrum_labels[i] if i < len(spectrum_labels) else f'Ph·ªï {i+1}'
                    ax.plot(x_data, y_data, color=colors[i], linewidth=1.5, alpha=0.7, label=label)

                ax.set_title(f"Preview ph·ªï Raman ({n_spectra} ph·ªï)")
                ax.set_xlabel("Wavenumber (cm‚Åª¬π)")
                ax.set_ylabel("Intensity")
                ax.legend(loc='best', fontsize=8)
                ax.grid(True, alpha=0.3)
                st.pyplot(fig)
                plt.close()

            elif hasattr(st.session_state.data, 'flat'):
                # Volumetric data - plot 5 ph·ªï ƒë·∫ßu v·ªõi m√†u kh√°c nhau
                sample_spectra = st.session_state.data.flat[0:5]
                n_samples = len(sample_spectra)
                colors = plt.cm.tab10(np.linspace(0, 1, n_samples))

                fig, ax = plt.subplots(figsize=(10, 4), dpi=150)
                for i in range(n_samples):
                    spec = sample_spectra[i]
                    if hasattr(spec, 'spectral_axis') and hasattr(spec, 'spectral_data'):
                        ax.plot(spec.spectral_axis, spec.spectral_data,
                               color=colors[i], linewidth=1.5, alpha=0.7, label=f'Ph·ªï {i+1}')

                ax.set_title("Preview ph·ªï Raman (5 ph·ªï ƒë·∫ßu)")
                ax.set_xlabel("Wavenumber (cm‚Åª¬π)")
                ax.set_ylabel("Intensity")
                ax.legend(loc='best', fontsize=8)
                ax.grid(True, alpha=0.3)
                st.pyplot(fig)
                plt.close()

            else:
                # Fallback
                sample_spectra = st.session_state.data
                fig, ax = plt.subplots(figsize=(10, 4), dpi=150)
                rp.plot.spectra(sample_spectra, ax=ax, plot_type='single')
                ax.set_title("Preview ph·ªï Raman")
                ax.set_xlabel("Wavenumber (cm‚Åª¬π)")
                ax.set_ylabel("Intensity")
                ax.grid(True, alpha=0.3)
                st.pyplot(fig)
                plt.close()

        except Exception as e:
            st.error(f"Kh√¥ng th·ªÉ hi·ªÉn th·ªã preview: {str(e)}")
            st.info(f"Debug: Data type = {type(st.session_state.data).__name__}")

# ==================== TRANG TI·ªÄN X·ª¨ L√ù ====================
elif page == "Ti·ªÅn x·ª≠ l√Ω":
    st.markdown('<p class="sub-header">‚öôÔ∏è Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu</p>', unsafe_allow_html=True)

    # Hi·ªÉn th·ªã th√¥ng tin collection n·∫øu c√≥
    if len(st.session_state.spectra_collection) > 0:
        selected_in_collection = [s for s in st.session_state.spectra_collection if s['selected']]
        if len(selected_in_collection) > 0:
            preprocessed_in_selected = sum(1 for s in selected_in_collection if s['preprocessed'] is not None)
            raw_in_selected = len(selected_in_collection) - preprocessed_in_selected

            if raw_in_selected > 0:
                st.info(f"üìö Collection: {len(selected_in_collection)} ph·ªï ƒë√£ ch·ªçn | ‚úÖ {preprocessed_in_selected} ƒë√£ x·ª≠ l√Ω | ‚ö™ {raw_in_selected} ch∆∞a x·ª≠ l√Ω")
            else:
                st.success(f"üìö Collection: {len(selected_in_collection)} ph·ªï ƒë√£ ch·ªçn | ‚úÖ T·∫•t c·∫£ ƒë√£ x·ª≠ l√Ω!")

    if st.session_state.data is None:
        st.warning("‚ö†Ô∏è Vui l√≤ng t·∫£i d·ªØ li·ªáu tr∆∞·ªõc!")
        st.stop()

    st.write("### X√¢y d·ª±ng Pipeline ti·ªÅn x·ª≠ l√Ω")

    # Sidebar cho vi·ªác ch·ªçn c√°c b∆∞·ªõc preprocessing
    st.write("#### Ch·ªçn c√°c b∆∞·ªõc ti·ªÅn x·ª≠ l√Ω:")

    col1, col2 = st.columns([1, 1])

    with col1:
        st.write("**B∆∞·ªõc 1: C·∫Øt v√πng ph·ªï (Cropping)**")
        use_cropping = st.checkbox("S·ª≠ d·ª•ng Cropping", value=True)
        if use_cropping:
            crop_min = st.number_input("Wavenumber min (cm‚Åª¬π):", 0, 4000, 700, 50)
            crop_max = st.number_input("Wavenumber max (cm‚Åª¬π):", 0, 4000, 1800, 50)

    with col2:
        st.write("**B∆∞·ªõc 2: Lo·∫°i b·ªè Cosmic Ray**")
        use_despike = st.checkbox("S·ª≠ d·ª•ng Despike", value=True)
        if use_despike:
            st.write("Ph∆∞∆°ng ph√°p: **WhitakerHayes**")
            with st.expander("‚öôÔ∏è T√πy ch·ªânh parameters"):
                despike_kernel = st.slider("Kernel size:", 1, 9, 3, 2, help="K√≠ch th∆∞·ªõc kernel ƒë·ªÉ detect spikes")
                despike_threshold = st.slider("Threshold:", 1.0, 20.0, 8.0, 1.0, help="Ng∆∞·ª°ng ƒë·ªÉ x√°c ƒë·ªãnh spike")

    col3, col4 = st.columns([1, 1])

    with col3:
        st.write("**B∆∞·ªõc 3: Kh·ª≠ nhi·ªÖu (Denoising)**")
        use_denoise = st.checkbox("S·ª≠ d·ª•ng Denoising", value=True)
        if use_denoise:
            denoise_method = st.selectbox(
                "Ph∆∞∆°ng ph√°p kh·ª≠ nhi·ªÖu:",
                ["SavGol", "Gaussian", "Wavelet"]
            )

            if denoise_method == "SavGol":
                window_length = st.slider("Window length:", 3, 21, 9, 2)
                polyorder = st.slider("Polynomial order:", 1, 5, 3)
            elif denoise_method == "Gaussian":
                sigma = st.slider("Sigma:", 0.5, 5.0, 1.0, 0.5)

    with col4:
        st.write("**B∆∞·ªõc 4: Hi·ªáu ch·ªânh Baseline**")
        use_baseline = st.checkbox("S·ª≠ d·ª•ng Baseline Correction", value=True)
        if use_baseline:
            baseline_method = st.selectbox(
                "Ph∆∞∆°ng ph√°p baseline:",
                ["ASPLS", "ASLS", "Poly"]
            )

            if baseline_method == "Poly":
                poly_order = st.slider("Polynomial order:", 1, 5, 3)

    col5, col6 = st.columns([1, 1])

    with col5:
        st.write("**B∆∞·ªõc 5: Chu·∫©n h√≥a (Normalization)**")
        use_normalize = st.checkbox("S·ª≠ d·ª•ng Normalization", value=True)
        if use_normalize:
            normalize_method = st.selectbox(
                "Ph∆∞∆°ng ph√°p chu·∫©n h√≥a:",
                ["MinMax", "AUC", "Vector", "SNV"]
            )

    # N√∫t √°p d·ª•ng pipeline
    st.markdown("---")
    col_btn1, col_btn2, col_btn3 = st.columns([1, 1, 1])

    with col_btn1:
        if st.button("‚ñ∂Ô∏è √Åp d·ª•ng Pipeline", type="primary", use_container_width=True):
            try:
                with st.spinner("ƒêang x·ª≠ l√Ω..."):
                    # X√¢y d·ª±ng pipeline
                    steps = []

                    if use_cropping:
                        steps.append(rp.preprocessing.misc.Cropper(region=(crop_min, crop_max)))

                    if use_despike:
                        steps.append(rp.preprocessing.despike.WhitakerHayes(
                            kernel_size=despike_kernel,
                            threshold=despike_threshold
                        ))

                    if use_denoise:
                        if denoise_method == "SavGol":
                            steps.append(rp.preprocessing.denoise.SavGol(window_length=window_length, polyorder=polyorder))
                        elif denoise_method == "Gaussian":
                            steps.append(rp.preprocessing.denoise.Gaussian(sigma=sigma))
                        else:
                            steps.append(rp.preprocessing.denoise.Wavelet())

                    if use_baseline:
                        if baseline_method == "ASPLS":
                            steps.append(rp.preprocessing.baseline.ASPLS())
                        elif baseline_method == "ASLS":
                            steps.append(rp.preprocessing.baseline.ASLS())
                        else:
                            steps.append(rp.preprocessing.baseline.Poly(poly_order=poly_order))

                    if use_normalize:
                        if normalize_method == "MinMax":
                            steps.append(rp.preprocessing.normalise.MinMax())
                        elif normalize_method == "AUC":
                            steps.append(rp.preprocessing.normalise.AUC())
                        elif normalize_method == "Vector":
                            steps.append(rp.preprocessing.normalise.Vector())
                        else:
                            steps.append(rp.preprocessing.normalise.SNV())

                    # T·∫°o v√† √°p d·ª•ng pipeline
                    pipeline = rp.preprocessing.Pipeline(steps)
                    st.session_state.preprocessed_data = pipeline.apply(st.session_state.data)
                    st.session_state.pipeline_steps = steps

                    st.success(f"‚úÖ ƒê√£ √°p d·ª•ng {len(steps)} b∆∞·ªõc ti·ªÅn x·ª≠ l√Ω!")

            except Exception as e:
                st.error(f"‚ùå L·ªói khi x·ª≠ l√Ω: {str(e)}")

    with col_btn2:
        if st.button("üîÑ Reset Pipeline", use_container_width=True):
            st.session_state.preprocessed_data = None
            st.session_state.pipeline_steps = []
            st.info("ƒê√£ reset pipeline")

    with col_btn3:
        # Batch preprocessing for collection
        selected_in_collection = [s for s in st.session_state.spectra_collection if s['selected']]
        if len(selected_in_collection) > 0:
            button_label = f"‚öôÔ∏è √Åp d·ª•ng cho Collection ({len(selected_in_collection)} ph·ªï)"
            if st.button(button_label, use_container_width=True, type="primary"):
                try:
                    with st.spinner(f"ƒêang x·ª≠ l√Ω {len(selected_in_collection)} ph·ªï..."):
                        # X√¢y d·ª±ng pipeline
                        steps = []

                        if use_cropping:
                            steps.append(rp.preprocessing.misc.Cropper(region=(crop_min, crop_max)))

                        if use_despike:
                            steps.append(rp.preprocessing.despike.WhitakerHayes(
                                kernel_size=despike_kernel,
                                threshold=despike_threshold
                            ))

                        if use_denoise:
                            if denoise_method == "SavGol":
                                steps.append(rp.preprocessing.denoise.SavGol(window_length=window_length, polyorder=polyorder))
                            elif denoise_method == "Gaussian":
                                steps.append(rp.preprocessing.denoise.Gaussian(sigma=sigma))
                            else:
                                steps.append(rp.preprocessing.denoise.Wavelet())

                        if use_baseline:
                            if baseline_method == "ASPLS":
                                steps.append(rp.preprocessing.baseline.ASPLS())
                            elif baseline_method == "ASLS":
                                steps.append(rp.preprocessing.baseline.ASLS())
                            else:
                                steps.append(rp.preprocessing.baseline.Poly(poly_order=poly_order))

                        if use_normalize:
                            if normalize_method == "MinMax":
                                steps.append(rp.preprocessing.normalise.MinMax())
                            elif normalize_method == "AUC":
                                steps.append(rp.preprocessing.normalise.AUC())
                            elif normalize_method == "Vector":
                                steps.append(rp.preprocessing.normalise.Vector())
                            else:
                                steps.append(rp.preprocessing.normalise.SNV())

                        # T·∫°o pipeline
                        pipeline = rp.preprocessing.Pipeline(steps)

                        # √Åp d·ª•ng cho t·ª´ng ph·ªï ƒë∆∞·ª£c ch·ªçn v·ªõi progress bar
                        success_count = 0
                        progress_bar = st.progress(0, text="B·∫Øt ƒë·∫ßu x·ª≠ l√Ω...")

                        for idx, item in enumerate(st.session_state.spectra_collection):
                            if item['selected']:
                                try:
                                    progress = (idx + 1) / len(selected_in_collection)
                                    progress_bar.progress(progress, text=f"ƒêang x·ª≠ l√Ω {item['name']}... ({idx + 1}/{len(selected_in_collection)})")

                                    item['preprocessed'] = pipeline.apply(item['data'])
                                    success_count += 1
                                except Exception as e:
                                    st.warning(f"L·ªói khi x·ª≠ l√Ω '{item['name']}': {str(e)}")

                        progress_bar.progress(1.0, text="‚úÖ Ho√†n th√†nh!")

                        st.success(f"‚úÖ ƒê√£ x·ª≠ l√Ω th√†nh c√¥ng {success_count}/{len(selected_in_collection)} ph·ªï v·ªõi {len(steps)} b∆∞·ªõc!")

                except Exception as e:
                    st.error(f"‚ùå L·ªói khi x·ª≠ l√Ω: {str(e)}")
        else:
            st.info("üí° Ch·ªçn ph·ªï trong Collection ƒë·ªÉ x·ª≠ l√Ω h√†ng lo·∫°t")

    # Combine section - K·∫øt h·ª£p ph·ªï ƒë·ªÉ ph√¢n t√≠ch (DI CHUY·ªÇN T·ª™ TAB T·∫¢I D·ªÆ LI·ªÜU)
    if len(st.session_state.spectra_collection) > 0:
        selected_in_collection = [s for s in st.session_state.spectra_collection if s['selected']]
        if len(selected_in_collection) > 1:
            st.markdown("---")
            st.write("### üîó K·∫øt h·ª£p ph·ªï ƒë·ªÉ ph√¢n t√≠ch")

            col_combine1, col_combine2 = st.columns([2, 1])

            # Calculate stats
            selected_preprocessed = sum(1 for s in selected_in_collection if s['preprocessed'] is not None)
            selected_raw = len(selected_in_collection) - selected_preprocessed

            with col_combine1:
                # Hi·ªÉn th·ªã warning n·∫øu c√≥ ph·ªï ch∆∞a x·ª≠ l√Ω
                if selected_raw > 0:
                    st.warning(f"‚ö†Ô∏è C√≥ {selected_raw} ph·ªï ch∆∞a ti·ªÅn x·ª≠ l√Ω. Khuy·∫øn ngh·ªã x·ª≠ l√Ω tr∆∞·ªõc khi k·∫øt h·ª£p.")
                else:
                    st.success(f"‚úÖ T·∫•t c·∫£ {len(selected_in_collection)} ph·ªï ƒë√£ ƒë∆∞·ª£c ti·ªÅn x·ª≠ l√Ω!")
                    st.info("üí° Click 'K·∫øt h·ª£p ph·ªï' ƒë·ªÉ t·∫°o SpectralContainer cho PCA")

            with col_combine2:
                # Combine spectra button
                if st.button("üîó K·∫øt h·ª£p ph·ªï", type="primary", use_container_width=True, key="combine_preprocessing"):
                    # Get selected items
                    selected_items = [s for s in st.session_state.spectra_collection if s['selected']]

                    try:
                        # ∆Øu ti√™n d√πng preprocessed data n·∫øu c√≥
                        spectra_arrays = []
                        using_preprocessed = False

                        for item in selected_items:
                            # D√πng preprocessed n·∫øu c√≥, kh√¥ng th√¨ d√πng raw
                            spec = item['preprocessed'] if item['preprocessed'] is not None else item['data']

                            if item['preprocessed'] is not None:
                                using_preprocessed = True

                            if hasattr(spec, 'spectral_data'):
                                spectra_arrays.append(spec.spectral_data)
                            else:
                                spectra_arrays.append(np.array(spec))

                        combined_array = np.stack(spectra_arrays)

                        # Get common spectral axis
                        first_spec = selected_items[0]['preprocessed'] if selected_items[0]['preprocessed'] is not None else selected_items[0]['data']
                        if hasattr(first_spec, 'spectral_axis'):
                            spectral_axis = first_spec.spectral_axis
                        else:
                            spectral_axis = np.arange(combined_array.shape[-1])

                        # Create SpectralContainer
                        st.session_state.data = rp.SpectralContainer(combined_array, spectral_axis=spectral_axis)
                        st.session_state.preprocessed_data = None

                        if using_preprocessed:
                            st.success(f"‚úÖ ƒê√£ k·∫øt h·ª£p {len(selected_in_collection)} ph·ªï (s·ª≠ d·ª•ng d·ªØ li·ªáu ƒë√£ ti·ªÅn x·ª≠ l√Ω)!")
                        else:
                            st.success(f"‚úÖ ƒê√£ k·∫øt h·ª£p {len(selected_in_collection)} ph·ªï (d·ªØ li·ªáu g·ªëc)!")
                            st.warning("‚ö†Ô∏è M·ªôt s·ªë ph·ªï ch∆∞a ƒë∆∞·ª£c ti·ªÅn x·ª≠ l√Ω. Khuy·∫øn ngh·ªã ti·ªÅn x·ª≠ l√Ω tr∆∞·ªõc khi ph√¢n t√≠ch.")

                        st.info("üí° Chuy·ªÉn sang tab 'Ph√¢n t√≠ch' ƒë·ªÉ ch·∫°y PCA.")
                        st.rerun()

                    except Exception as e:
                        st.error(f"‚ùå L·ªói khi k·∫øt h·ª£p ph·ªï: {str(e)}")

    # So s√°nh tr∆∞·ªõc/sau
    if st.session_state.preprocessed_data is not None:
        st.markdown("---")
        st.write("### üìä So s√°nh tr∆∞·ªõc v√† sau x·ª≠ l√Ω")

        col_before, col_after = st.columns(2)

        try:
            # L·∫•y ph·ªï m·∫´u
            data_type = type(st.session_state.data).__name__

            if data_type == 'Spectrum':
                # Spectrum ƒë∆°n l·∫ª
                raw_spectrum = st.session_state.data
                processed_spectrum = st.session_state.preprocessed_data
            elif hasattr(st.session_state.data, 'flat'):
                # Volumetric data
                raw_spectrum = st.session_state.data.flat[0]
                processed_spectrum = st.session_state.preprocessed_data.flat[0]
            elif hasattr(st.session_state.data, '__len__') and len(st.session_state.data.shape) > 1:
                # Multi-spectrum data
                raw_spectrum = st.session_state.data[0]
                processed_spectrum = st.session_state.preprocessed_data[0]
            else:
                raw_spectrum = st.session_state.data
                processed_spectrum = st.session_state.preprocessed_data

            with col_before:
                st.write("**Tr∆∞·ªõc x·ª≠ l√Ω**")
                fig1, ax1 = plt.subplots(figsize=(6, 4), dpi=150)

                # Plot tr·ª±c ti·∫øp v·ªõi matplotlib ƒë·ªÉ tr√°nh l·ªói indexing
                if hasattr(raw_spectrum, 'spectral_axis') and hasattr(raw_spectrum, 'spectral_data'):
                    ax1.plot(raw_spectrum.spectral_axis, raw_spectrum.spectral_data, linewidth=1.5)
                    ax1.set_xlabel("Wavenumber (cm‚Åª¬π)")
                    ax1.set_ylabel("Intensity")
                else:
                    rp.plot.spectra(raw_spectrum, ax=ax1)

                ax1.set_title("Ph·ªï g·ªëc")
                ax1.grid(True, alpha=0.3)
                plot_with_download(fig1, "raw_spectrum.png", "üì• T·∫£i ph·ªï g·ªëc")

            with col_after:
                st.write("**Sau x·ª≠ l√Ω**")
                fig2, ax2 = plt.subplots(figsize=(6, 4), dpi=150)

                # Plot tr·ª±c ti·∫øp v·ªõi matplotlib ƒë·ªÉ tr√°nh l·ªói indexing
                if hasattr(processed_spectrum, 'spectral_axis') and hasattr(processed_spectrum, 'spectral_data'):
                    ax2.plot(processed_spectrum.spectral_axis, processed_spectrum.spectral_data, linewidth=1.5)
                    ax2.set_xlabel("Wavenumber (cm‚Åª¬π)")
                    ax2.set_ylabel("Intensity")
                else:
                    rp.plot.spectra(processed_spectrum, ax=ax2)

                ax2.set_title("Ph·ªï ƒë√£ x·ª≠ l√Ω")
                ax2.grid(True, alpha=0.3)
                plot_with_download(fig2, "preprocessed_spectrum.png", "üì• T·∫£i ph·ªï ƒë√£ x·ª≠ l√Ω")

        except Exception as e:
            st.error(f"L·ªói khi hi·ªÉn th·ªã so s√°nh: {str(e)}")

        # CSV Export cho preprocessing data
        st.markdown("---")
        st.write("### üì• T·∫£i d·ªØ li·ªáu ti·ªÅn x·ª≠ l√Ω")

        col_csv1, col_csv2 = st.columns(2)

        with col_csv1:
            st.write("**Ph·ªï g·ªëc**")
            if hasattr(raw_spectrum, 'spectral_axis') and hasattr(raw_spectrum, 'spectral_data'):
                raw_df = pd.DataFrame({
                    'Wavenumber (cm‚Åª¬π)': raw_spectrum.spectral_axis,
                    'Intensity': raw_spectrum.spectral_data
                })
                create_csv_download(raw_df, "raw_spectrum.csv", "üì• T·∫£i ph·ªï g·ªëc CSV")
            else:
                st.info("Kh√¥ng th·ªÉ export d·ªØ li·ªáu n√†y")

        with col_csv2:
            st.write("**Ph·ªï ƒë√£ x·ª≠ l√Ω**")
            if hasattr(processed_spectrum, 'spectral_axis') and hasattr(processed_spectrum, 'spectral_data'):
                processed_df = pd.DataFrame({
                    'Wavenumber (cm‚Åª¬π)': processed_spectrum.spectral_axis,
                    'Intensity': processed_spectrum.spectral_data
                })
                create_csv_download(processed_df, "preprocessed_spectrum.csv", "üì• T·∫£i ph·ªï ƒë√£ x·ª≠ l√Ω CSV")
            else:
                st.info("Kh√¥ng th·ªÉ export d·ªØ li·ªáu n√†y")

    # Overlay plots cho batch preprocessing
    if len(st.session_state.spectra_collection) > 0:
        selected_in_collection = [s for s in st.session_state.spectra_collection if s['selected']]
        preprocessed_count = sum(1 for s in selected_in_collection if s['preprocessed'] is not None)

        if len(selected_in_collection) > 1 and preprocessed_count > 0:
            st.markdown("---")
            st.write("### üìä So s√°nh ch·ªìng ph·ªï (Overlay)")
            st.info(f"Hi·ªÉn th·ªã {len(selected_in_collection)} ph·ªï ƒë√£ ch·ªçn trong Collection ({preprocessed_count} ƒë√£ x·ª≠ l√Ω)")

            try:
                # T·∫°o figure v·ªõi 2 subplots
                fig, (ax_raw, ax_processed) = plt.subplots(1, 2, figsize=(14, 5), dpi=150)

                # Colormap cho m√†u s·∫Øc ƒë·∫πp
                colors = plt.cm.tab10(np.linspace(0, 1, len(selected_in_collection)))

                # Plot raw spectra (b√™n tr√°i)
                ax_raw.set_title("Ph·ªï g·ªëc (Raw Spectra)", fontsize=12, fontweight='bold')
                ax_raw.set_xlabel("Wavenumber (cm‚Åª¬π)")
                ax_raw.set_ylabel("Intensity")
                ax_raw.grid(True, alpha=0.3)

                for idx, item in enumerate(selected_in_collection):
                    raw_spec = item['data']

                    # Extract data safely
                    if hasattr(raw_spec, 'spectral_axis') and hasattr(raw_spec, 'spectral_data'):
                        x_data = raw_spec.spectral_axis
                        y_data = raw_spec.spectral_data
                    elif hasattr(raw_spec, 'spectral_axis'):
                        x_data = raw_spec.spectral_axis
                        y_data = np.array(raw_spec)
                    else:
                        y_data = np.array(raw_spec)
                        x_data = np.arange(len(y_data))

                    # Flatten if needed
                    if len(y_data.shape) > 1:
                        y_data = y_data.flatten()

                    ax_raw.plot(x_data, y_data, color=colors[idx], linewidth=1.5, alpha=0.7, label=item['name'])

                ax_raw.legend(loc='best', fontsize=8, framealpha=0.9)

                # Plot preprocessed spectra (b√™n ph·∫£i)
                ax_processed.set_title("Ph·ªï ƒë√£ x·ª≠ l√Ω (Preprocessed Spectra)", fontsize=12, fontweight='bold')
                ax_processed.set_xlabel("Wavenumber (cm‚Åª¬π)")
                ax_processed.set_ylabel("Intensity")
                ax_processed.grid(True, alpha=0.3)

                preprocessed_items = [item for item in selected_in_collection if item['preprocessed'] is not None]

                if len(preprocessed_items) > 0:
                    # Re-create colors for preprocessed items
                    proc_colors = plt.cm.tab10(np.linspace(0, 1, len(preprocessed_items)))

                    for idx, item in enumerate(preprocessed_items):
                        proc_spec = item['preprocessed']

                        # Extract data safely
                        if hasattr(proc_spec, 'spectral_axis') and hasattr(proc_spec, 'spectral_data'):
                            x_data = proc_spec.spectral_axis
                            y_data = proc_spec.spectral_data
                        elif hasattr(proc_spec, 'spectral_axis'):
                            x_data = proc_spec.spectral_axis
                            y_data = np.array(proc_spec)
                        else:
                            y_data = np.array(proc_spec)
                            x_data = np.arange(len(y_data))

                        # Flatten if needed
                        if len(y_data.shape) > 1:
                            y_data = y_data.flatten()

                        ax_processed.plot(x_data, y_data, color=proc_colors[idx], linewidth=1.5, alpha=0.7, label=item['name'])

                    ax_processed.legend(loc='best', fontsize=8, framealpha=0.9)
                else:
                    ax_processed.text(0.5, 0.5, 'Ch∆∞a c√≥ ph·ªï n√†o ƒë∆∞·ª£c x·ª≠ l√Ω',
                                     ha='center', va='center', transform=ax_processed.transAxes,
                                     fontsize=12, style='italic')

                plt.tight_layout()
                plot_with_download(fig, "batch_preprocessing_overlay.png", "üì• T·∫£i overlay plots")

                # CSV Export cho batch preprocessing
                st.markdown("---")
                st.write("### üì• T·∫£i d·ªØ li·ªáu batch preprocessing")

                col_batch1, col_batch2 = st.columns(2)

                with col_batch1:
                    st.write("**T·∫•t c·∫£ ph·ªï g·ªëc**")
                    try:
                        # T·∫°o DataFrame cho t·∫•t c·∫£ ph·ªï raw
                        raw_data_dict = {}
                        wavenumbers = None

                        for item in selected_in_collection:
                            raw_spec = item['data']
                            if hasattr(raw_spec, 'spectral_axis') and hasattr(raw_spec, 'spectral_data'):
                                if wavenumbers is None:
                                    wavenumbers = raw_spec.spectral_axis
                                y_data = raw_spec.spectral_data
                                if len(y_data.shape) > 1:
                                    y_data = y_data.flatten()
                                raw_data_dict[item['name']] = y_data

                        if wavenumbers is not None and len(raw_data_dict) > 0:
                            raw_batch_df = pd.DataFrame(raw_data_dict)
                            raw_batch_df.insert(0, 'Wavenumber (cm‚Åª¬π)', wavenumbers)
                            create_csv_download(raw_batch_df, "batch_raw_spectra.csv", "üì• T·∫£i t·∫•t c·∫£ ph·ªï g·ªëc CSV")
                        else:
                            st.info("Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ export")
                    except Exception as e:
                        st.warning(f"Kh√¥ng th·ªÉ export: {str(e)}")

                with col_batch2:
                    st.write("**T·∫•t c·∫£ ph·ªï ƒë√£ x·ª≠ l√Ω**")
                    if len(preprocessed_items) > 0:
                        try:
                            # T·∫°o DataFrame cho t·∫•t c·∫£ ph·ªï preprocessed
                            proc_data_dict = {}
                            wavenumbers = None

                            for item in preprocessed_items:
                                proc_spec = item['preprocessed']
                                if hasattr(proc_spec, 'spectral_axis') and hasattr(proc_spec, 'spectral_data'):
                                    if wavenumbers is None:
                                        wavenumbers = proc_spec.spectral_axis
                                    y_data = proc_spec.spectral_data
                                    if len(y_data.shape) > 1:
                                        y_data = y_data.flatten()
                                    proc_data_dict[item['name']] = y_data

                            if wavenumbers is not None and len(proc_data_dict) > 0:
                                proc_batch_df = pd.DataFrame(proc_data_dict)
                                proc_batch_df.insert(0, 'Wavenumber (cm‚Åª¬π)', wavenumbers)
                                create_csv_download(proc_batch_df, "batch_preprocessed_spectra.csv", "üì• T·∫£i t·∫•t c·∫£ ph·ªï ƒë√£ x·ª≠ l√Ω CSV")
                            else:
                                st.info("Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ export")
                        except Exception as e:
                            st.warning(f"Kh√¥ng th·ªÉ export: {str(e)}")
                    else:
                        st.info("Ch∆∞a c√≥ ph·ªï n√†o ƒë∆∞·ª£c ti·ªÅn x·ª≠ l√Ω")

            except Exception as e:
                st.error(f"L·ªói khi hi·ªÉn th·ªã overlay plots: {str(e)}")

        # Stacked plots cho batch preprocessing
        if len(selected_in_collection) > 1:
            st.markdown("---")
            st.write("### üìö So s√°nh ph·ªï d·∫°ng Stacked")
            st.info("Stacked plot gi√∫p so s√°nh t·ª´ng ph·ªï ri√™ng l·∫ª b·∫±ng c√°ch x·∫øp ch·ªìng v·ªõi offset theo tr·ª•c Y")

            # Options
            col_opt1, col_opt2, col_opt3 = st.columns([2, 2, 1])

            with col_opt1:
                stack_mode = st.radio(
                    "Ch·ªçn d·ªØ li·ªáu:",
                    ["Ph·ªï g·ªëc", "Ph·ªï ƒë√£ x·ª≠ l√Ω", "So s√°nh c·∫£ 2"],
                    horizontal=True
                )

            with col_opt2:
                offset_multiplier = st.slider(
                    "Kho·∫£ng c√°ch gi·ªØa c√°c ph·ªï:",
                    min_value=0.5,
                    max_value=3.0,
                    value=1.0,
                    step=0.1,
                    help="ƒêi·ªÅu ch·ªânh kho·∫£ng c√°ch offset gi·ªØa c√°c ph·ªï"
                )

            with col_opt3:
                reverse_order = st.checkbox("ƒê·∫£o ng∆∞·ª£c th·ª© t·ª±", value=False)

            try:
                if stack_mode == "So s√°nh c·∫£ 2":
                    fig, (ax_raw_stack, ax_proc_stack) = plt.subplots(1, 2, figsize=(14, 8), dpi=150)
                    axes_list = [ax_raw_stack, ax_proc_stack]
                    titles = ["Ph·ªï g·ªëc (Stacked)", "Ph·ªï ƒë√£ x·ª≠ l√Ω (Stacked)"]
                else:
                    fig, ax = plt.subplots(1, 1, figsize=(10, 8), dpi=150)
                    axes_list = [ax]
                    titles = [f"{stack_mode} (Stacked)"]

                colors = plt.cm.tab10(np.linspace(0, 1, len(selected_in_collection)))

                # Determine order
                items_to_plot = list(reversed(selected_in_collection)) if reverse_order else selected_in_collection

                for ax_idx, ax_current in enumerate(axes_list):
                    # Determine which data to use
                    if stack_mode == "Ph·ªï g·ªëc" or (stack_mode == "So s√°nh c·∫£ 2" and ax_idx == 0):
                        use_raw = True
                    else:
                        use_raw = False

                    # Filter items based on data availability
                    if use_raw:
                        items = items_to_plot
                    else:
                        items = [item for item in items_to_plot if item['preprocessed'] is not None]

                    if len(items) == 0:
                        ax_current.text(0.5, 0.5, 'Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ hi·ªÉn th·ªã',
                                      ha='center', va='center', transform=ax_current.transAxes,
                                      fontsize=12, style='italic')
                        ax_current.set_title(titles[ax_idx], fontsize=12, fontweight='bold')
                        continue

                    # Calculate offset
                    max_intensity = 0
                    all_intensities = []
                    for item in items:
                        spec = item['data'] if use_raw else item['preprocessed']
                        if hasattr(spec, 'spectral_data'):
                            y = spec.spectral_data
                        else:
                            y = np.array(spec)
                        if len(y.shape) > 1:
                            y = y.flatten()
                        all_intensities.append(y)
                        max_intensity = max(max_intensity, np.max(y) - np.min(y))

                    offset = max_intensity * offset_multiplier

                    # Plot each spectrum with offset
                    for idx, item in enumerate(items):
                        spec = item['data'] if use_raw else item['preprocessed']

                        # Extract data safely
                        if hasattr(spec, 'spectral_axis') and hasattr(spec, 'spectral_data'):
                            x_data = spec.spectral_axis
                            y_data = spec.spectral_data
                        elif hasattr(spec, 'spectral_axis'):
                            x_data = spec.spectral_axis
                            y_data = np.array(spec)
                        else:
                            y_data = np.array(spec)
                            x_data = np.arange(len(y_data))

                        # Flatten if needed
                        if len(y_data.shape) > 1:
                            y_data = y_data.flatten()

                        # Apply offset
                        y_offset = y_data + (idx * offset)

                        # Find color index in original list
                        original_idx = selected_in_collection.index(item)
                        color = colors[original_idx]

                        # Plot
                        ax_current.plot(x_data, y_offset, color=color, linewidth=1.2, alpha=0.9, label=item['name'])

                        # Add text label - ƒë·∫∑t g·∫ßn cu·ªëi ph·ªï, v√†o trong plot m·ªôt ch√∫t
                        # D√πng 92% c·ªßa chi·ªÅu d√†i ƒë·ªÉ text n·∫±m ho√†n to√†n trong plot
                        label_idx = int(len(x_data) * 0.92)
                        # Th√™m offset nh·ªè ƒë·ªÉ text cao h∆°n data m·ªôt ch√∫t (10% c·ªßa offset gi·ªØa c√°c ph·ªï)
                        text_y_offset = y_offset[label_idx] + (offset * 0.1)
                        ax_current.text(x_data[label_idx], text_y_offset, item['name'],
                                      fontsize=8, va='bottom', ha='right', color=color, fontweight='bold',
                                      bbox=dict(boxstyle='round,pad=0.3', facecolor='white', edgecolor=color, alpha=0.8))

                    ax_current.set_title(titles[ax_idx], fontsize=12, fontweight='bold')
                    ax_current.set_xlabel("Wavenumber (cm‚Åª¬π)")
                    ax_current.set_ylabel("Intensity (offset)")
                    ax_current.grid(True, alpha=0.2, axis='x')
                    ax_current.legend(loc='upper right', fontsize=8, framealpha=0.9)

                plt.tight_layout()

                # Download button
                if stack_mode == "So s√°nh c·∫£ 2":
                    plot_with_download(fig, "batch_stacked_comparison.png", "üì• T·∫£i Stacked Plots")
                elif stack_mode == "Ph·ªï g·ªëc":
                    plot_with_download(fig, "batch_stacked_raw.png", "üì• T·∫£i Stacked Plot")
                else:
                    plot_with_download(fig, "batch_stacked_preprocessed.png", "üì• T·∫£i Stacked Plot")

            except Exception as e:
                st.error(f"L·ªói khi hi·ªÉn th·ªã stacked plots: {str(e)}")

# ==================== TRANG PH√ÇN T√çCH ====================
elif page == "Ph√¢n t√≠ch":
    st.markdown('<p class="sub-header">üî¨ Ph√¢n t√≠ch ph·ªï</p>', unsafe_allow_html=True)

    # Ki·ªÉm tra d·ªØ li·ªáu
    if st.session_state.data is None:
        st.warning("‚ö†Ô∏è Vui l√≤ng t·∫£i d·ªØ li·ªáu tr∆∞·ªõc!")
        st.stop()

    # S·ª≠ d·ª•ng d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω n·∫øu c√≥, kh√¥ng th√¨ d√πng d·ªØ li·ªáu g·ªëc
    data_to_analyze = st.session_state.preprocessed_data if st.session_state.preprocessed_data is not None else st.session_state.data

    if st.session_state.preprocessed_data is None:
        st.info("üí° ƒêang s·ª≠ d·ª•ng d·ªØ li·ªáu g·ªëc. Khuy·∫øn ngh·ªã ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu tr∆∞·ªõc khi ph√¢n t√≠ch.")

    # Debug info
    st.write(f"**Lo·∫°i d·ªØ li·ªáu ph√¢n t√≠ch:** {type(data_to_analyze).__name__}")

    st.write("### Ch·ªçn ph∆∞∆°ng ph√°p ph√¢n t√≠ch")

    # Warning v·ªÅ N-FINDR compatibility
    with st.expander("‚ö†Ô∏è L∆∞u √Ω v·ªÅ Spectral Unmixing (N-FINDR)", expanded=False):
        st.warning("""
        **N-FINDR c√≥ th·ªÉ g·∫∑p l·ªói compatibility v·ªõi scipy!**

        N·∫øu b·∫°n g·∫∑p l·ªói `module 'scipy.linalg' has no attribute '_flinalg'`,
        ƒë√¢y l√† v·∫•n ƒë·ªÅ ƒë√£ bi·∫øt c·ªßa RamanSPy v·ªõi m·ªôt s·ªë phi√™n b·∫£n scipy.

        **Khuy·∫øn ngh·ªã**: S·ª≠ d·ª•ng **PCA (Component Analysis)** thay th·∫ø -
        ho·∫°t ƒë·ªông t·ªët, ·ªïn ƒë·ªãnh, v√† cho k·∫øt qu·∫£ t∆∞∆°ng t·ª±!
        """)

    analysis_method = st.selectbox(
        "Ph∆∞∆°ng ph√°p:",
        ["Component Analysis (PCA)", "Peak Detection", "Spectral Unmixing (N-FINDR)"]
    )

    # Spectral Unmixing
    if analysis_method == "Spectral Unmixing (N-FINDR)":
        st.write("#### Spectral Unmixing - N-FINDR")
        st.write("Ph√¢n t√°ch ph·ªï th√†nh c√°c th√†nh ph·∫ßn endmember v√† b·∫£n ƒë·ªì phong ph√∫")

        col1, col2 = st.columns([2, 1])

        with col1:
            n_endmembers = st.slider("S·ªë endmembers:", 2, 10, 5)

        with col2:
            st.info("üí° S·ªë endmembers l√† s·ªë th√†nh ph·∫ßn c∆° b·∫£n trong m·∫´u")

        if st.button("‚ñ∂Ô∏è Ch·∫°y Unmixing", type="primary"):
            try:
                # Ki·ªÉm tra n·∫øu l√† Spectrum ƒë∆°n l·∫ª
                data_type = type(data_to_analyze).__name__

                # Ki·ªÉm tra shape ƒë·ªÉ x√°c ƒë·ªãnh c√≥ ph·∫£i single spectrum kh√¥ng
                if data_type == 'Spectrum':
                    if hasattr(data_to_analyze, 'spectral_data'):
                        data_shape = data_to_analyze.spectral_data.shape
                    else:
                        data_shape = data_to_analyze.shape if hasattr(data_to_analyze, 'shape') else (1,)

                    # N·∫øu l√† 1D ho·∫∑c shape[0] == 1, l√† single spectrum
                    if len(data_shape) == 1 or (len(data_shape) > 1 and data_shape[0] == 1):
                        st.error("‚ùå Spectral Unmixing c·∫ßn nhi·ªÅu ph·ªï (·∫£nh ho·∫∑c volumetric data).")
                        st.info("üí° V·ªõi 1 ph·ªï ƒë∆°n l·∫ª, s·ª≠ d·ª•ng Peak Detection thay v√¨ Unmixing.")
                        st.stop()

                with st.spinner("ƒêang ph√¢n t√≠ch..."):
                    try:
                        unmixer = rp.analysis.unmix.NFINDR(n_endmembers=n_endmembers)
                        abundance_maps, endmembers = unmixer.apply(data_to_analyze)
                    except AttributeError as ae:
                        if "_flinalg" in str(ae) or "scipy.linalg" in str(ae):
                            st.error("‚ùå L·ªói scipy compatibility v·ªõi N-FINDR")
                            st.warning("""
                            **Nguy√™n nh√¢n**: RamanSPy's N-FINDR implementation c√≥ v·∫•n ƒë·ªÅ compatibility v·ªõi phi√™n b·∫£n scipy hi·ªán t·∫°i.

                            **Gi·∫£i ph√°p**:
                            1. S·ª≠ d·ª•ng **PCA** thay v√¨ N-FINDR cho vi·ªác ph√¢n t√≠ch th√†nh ph·∫ßn
                            2. Ho·∫∑c c·∫≠p nh·∫≠t RamanSPy/scipy:
                               ```
                               pip install --upgrade ramanspy scipy
                               ```

                            **Khuy·∫øn ngh·ªã**: S·ª≠ d·ª•ng PCA (Component Analysis) - ho·∫°t ƒë·ªông t·ªët v√† ·ªïn ƒë·ªãnh h∆°n!
                            """)
                            st.stop()
                        else:
                            raise ae

                    st.session_state.analysis_results = {
                        'type': 'unmixing',
                        'abundance_maps': abundance_maps,
                        'endmembers': endmembers,
                        'data': data_to_analyze
                    }

                    st.success(f"‚úÖ ƒê√£ ph√¢n t√°ch th√†nh {n_endmembers} endmembers!")

            except Exception as e:
                st.error(f"‚ùå L·ªói khi ph√¢n t√≠ch: {str(e)}")

    # Peak Detection
    elif analysis_method == "Peak Detection":
        st.write("#### Peak Detection")
        st.write("T√¨m c√°c peak trong ph·ªï")

        # Check if we have Collection with multiple spectra
        selected_in_collection = [s for s in st.session_state.spectra_collection if s['selected']]
        has_collection = len(selected_in_collection) > 0

        # Options for multi-spectrum analysis
        if has_collection and len(selected_in_collection) > 1:
            st.info(f"üìä Ph√°t hi·ªán {len(selected_in_collection)} ph·ªï trong Collection")

            col_mode1, col_mode2 = st.columns([2, 1])
            with col_mode1:
                peak_mode = st.radio(
                    "Ch·∫ø ƒë·ªô ph√¢n t√≠ch:",
                    ["Ph·ªï ƒë∆°n l·∫ª", "So s√°nh t·∫•t c·∫£ ph·ªï"],
                    horizontal=True,
                    help="Ch·ªçn ph√¢n t√≠ch m·ªôt ph·ªï ri√™ng l·∫ª ho·∫∑c xem t·∫•t c·∫£ peaks c√πng l√∫c"
                )

            if peak_mode == "Ph·ªï ƒë∆°n l·∫ª":
                spectrum_options = [item['name'] for item in selected_in_collection]
                selected_spectrum_name = st.selectbox(
                    "Ch·ªçn ph·ªï ƒë·ªÉ ph√¢n t√≠ch:",
                    spectrum_options
                )
                selected_spectrum_idx = spectrum_options.index(selected_spectrum_name)
            else:
                selected_spectrum_idx = None  # Analyze all
        else:
            peak_mode = "Ph·ªï ƒë∆°n l·∫ª"
            selected_spectrum_idx = 0
            if has_collection:
                st.info(f"üìä Ph√¢n t√≠ch ph·ªï: {selected_in_collection[0]['name']}")

        col1, col2 = st.columns(2)

        with col1:
            prominence = st.slider("Prominence:", 0.01, 1.0, 0.1, 0.01)

        with col2:
            distance = st.slider("Distance (s·ªë ƒëi·ªÉm):", 5, 100, 20)

        if st.button("‚ñ∂Ô∏è T√¨m Peaks", type="primary"):
            try:
                from scipy.signal import find_peaks

                with st.spinner("ƒêang t√¨m peaks..."):
                    # Prepare results storage
                    all_peaks_results = []

                    # Determine which spectra to analyze
                    if has_collection:
                        if peak_mode == "So s√°nh t·∫•t c·∫£ ph·ªï":
                            spectra_to_analyze = selected_in_collection
                        else:
                            spectra_to_analyze = [selected_in_collection[selected_spectrum_idx]]
                    else:
                        # No collection, use single spectrum
                        data_type = type(data_to_analyze).__name__
                        if data_type == 'Spectrum':
                            spectrum = data_to_analyze
                        elif hasattr(data_to_analyze, 'flat'):
                            spectrum = data_to_analyze.flat[0]
                        elif hasattr(data_to_analyze, '__len__') and len(data_to_analyze.shape) > 1:
                            spectrum = data_to_analyze[0]
                        else:
                            spectrum = data_to_analyze

                        spectra_to_analyze = [{'name': 'Ph·ªï', 'data': spectrum}]

                    # Analyze each spectrum
                    for item in spectra_to_analyze:
                        spectrum = item['data']
                        spectrum_name = item['name']

                        # Use preprocessed if available
                        if 'preprocessed' in item and item['preprocessed'] is not None:
                            spectrum = item['preprocessed']

                        # L·∫•y intensities m·ªôt c√°ch an to√†n
                        if hasattr(spectrum, 'spectral_data'):
                            intensities = spectrum.spectral_data
                        elif hasattr(spectrum, 'flat'):
                            intensities = spectrum.flat
                        elif isinstance(spectrum, np.ndarray):
                            intensities = spectrum
                        else:
                            intensities = np.array(spectrum)

                        # ƒê·∫£m b·∫£o l√† 1D array
                        if len(intensities.shape) > 1:
                            intensities = intensities.flatten()

                        # T√¨m peaks
                        peaks, properties = find_peaks(intensities, prominence=prominence, distance=distance)

                        # L·∫•y spectral axis an to√†n
                        if hasattr(spectrum, 'spectral_axis'):
                            spectral_axis = spectrum.spectral_axis
                        else:
                            spectral_axis = np.arange(len(intensities))

                        all_peaks_results.append({
                            'name': spectrum_name,
                            'spectrum': spectrum,
                            'peaks': peaks,
                            'properties': properties,
                            'intensities': intensities,
                            'spectral_axis': spectral_axis
                        })

                    st.session_state.analysis_results = {
                        'type': 'peaks',
                        'all_peaks': all_peaks_results,
                        'mode': peak_mode
                    }

                    total_peaks = sum(len(r['peaks']) for r in all_peaks_results)
                    if peak_mode == "So s√°nh t·∫•t c·∫£ ph·ªï":
                        st.success(f"‚úÖ ƒê√£ t√¨m th·∫•y t·ªïng c·ªông {total_peaks} peaks trong {len(all_peaks_results)} ph·ªï!")
                    else:
                        st.success(f"‚úÖ ƒê√£ t√¨m th·∫•y {total_peaks} peaks!")

            except Exception as e:
                st.error(f"‚ùå L·ªói khi t√¨m peaks: {str(e)}")

    # PCA
    elif analysis_method == "Component Analysis (PCA)":
        st.write("#### Principal Component Analysis (PCA)")
        st.write("Ph√¢n t√≠ch th√†nh ph·∫ßn ch√≠nh")

        n_components = st.slider("S·ªë components:", 2, 10, 3)

        if st.button("‚ñ∂Ô∏è Ch·∫°y PCA", type="primary"):
            try:
                from sklearn.decomposition import PCA

                with st.spinner("ƒêang ph√¢n t√≠ch PCA..."):
                    # Chu·∫©n b·ªã d·ªØ li·ªáu
                    data_type = type(data_to_analyze).__name__

                    if data_type == 'Spectrum':
                        # Spectrum ƒë∆°n l·∫ª - PCA c·∫ßn √≠t nh·∫•t 2 m·∫´u
                        st.error("‚ùå PCA c·∫ßn √≠t nh·∫•t 2 ph·ªï. D·ªØ li·ªáu hi·ªán t·∫°i ch·ªâ c√≥ 1 ph·ªï ƒë∆°n l·∫ª.")
                        st.info("üí° S·ª≠ d·ª•ng d·ªØ li·ªáu t·ªïng h·ª£p ho·∫∑c t·∫£i nhi·ªÅu ph·ªï ƒë·ªÉ ch·∫°y PCA.")
                        st.stop()
                    elif hasattr(data_to_analyze, 'flat'):
                        # Volumetric data
                        data_matrix = data_to_analyze.flat.spectral_data
                    else:
                        data_matrix = data_to_analyze.spectral_data if hasattr(data_to_analyze, 'spectral_data') else data_to_analyze

                    # Reshape n·∫øu c·∫ßn
                    if len(data_matrix.shape) > 2:
                        original_shape = data_matrix.shape
                        data_matrix = data_matrix.reshape(-1, data_matrix.shape[-1])
                    elif len(data_matrix.shape) == 1:
                        # N·∫øu ch·ªâ c√≥ 1 ph·ªï, kh√¥ng th·ªÉ ch·∫°y PCA
                        st.error("‚ùå PCA c·∫ßn √≠t nh·∫•t 2 ph·ªï ƒë·ªÉ ph√¢n t√≠ch.")
                        st.stop()

                    # Ch·∫°y PCA
                    pca = PCA(n_components=n_components)
                    scores = pca.fit_transform(data_matrix)
                    loadings = pca.components_

                    # L·∫•y t√™n ph·ªï t·ª´ Collection n·∫øu c√≥
                    spectrum_names = []
                    if len(st.session_state.spectra_collection) > 0:
                        # L·∫•y selected items
                        selected_items = [s for s in st.session_state.spectra_collection if s['selected']]
                        if len(selected_items) > 0:
                            spectrum_names = [item['name'] for item in selected_items]

                    st.session_state.analysis_results = {
                        'type': 'pca',
                        'scores': scores,
                        'loadings': loadings,
                        'explained_variance': pca.explained_variance_ratio_,
                        'data': data_to_analyze,
                        'spectrum_names': spectrum_names,
                        'n_components': n_components
                    }

                    st.success(f"‚úÖ ƒê√£ ho√†n th√†nh PCA v·ªõi {n_components} components!")

            except Exception as e:
                st.error(f"‚ùå L·ªói khi ch·∫°y PCA: {str(e)}")

# ==================== TRANG TR·ª∞C QUAN H√ìA ====================
elif page == "Tr·ª±c quan h√≥a":
    st.markdown('<p class="sub-header">üìä Tr·ª±c quan h√≥a k·∫øt qu·∫£</p>', unsafe_allow_html=True)

    if st.session_state.analysis_results is None:
        st.warning("‚ö†Ô∏è Vui l√≤ng ch·∫°y ph√¢n t√≠ch tr∆∞·ªõc!")
        st.stop()

    results = st.session_state.analysis_results
    result_type = results['type']

    # Hi·ªÉn th·ªã theo lo·∫°i ph√¢n t√≠ch
    if result_type == 'unmixing':
        st.write("### K·∫øt qu·∫£ Spectral Unmixing")

        endmembers = results['endmembers']
        abundance_maps = results['abundance_maps']
        data = results['data']

        # Plot endmembers
        st.write("#### üî¨ Endmembers")
        fig1, ax1 = plt.subplots(figsize=(12, 6), dpi=150)

        if hasattr(data, 'spectral_axis'):
            rp.plot.spectra(endmembers, wavenumber_axis=data.spectral_axis, ax=ax1, plot_type='single stacked')
        else:
            rp.plot.spectra(endmembers, ax=ax1, plot_type='single stacked')

        ax1.set_title("Endmember Spectra")
        plot_with_download(fig1, "unmixing_endmembers.png", "üì• T·∫£i Endmembers")

        # Plot abundance maps
        st.write("#### üó∫Ô∏è Abundance Maps")

        try:
            # N·∫øu l√† volumetric data, l·∫•y m·ªôt layer
            if len(abundance_maps[0].shape) == 3:
                layer_idx = st.slider("Ch·ªçn layer:", 0, abundance_maps[0].shape[2]-1, abundance_maps[0].shape[2]//2)

                fig2, axes = plt.subplots(1, len(abundance_maps), figsize=(4*len(abundance_maps), 4), dpi=150)
                if len(abundance_maps) == 1:
                    axes = [axes]

                for i, (amap, ax) in enumerate(zip(abundance_maps, axes)):
                    im = ax.imshow(amap[:, :, layer_idx], cmap='viridis')
                    ax.set_title(f"Endmember {i+1}")
                    plt.colorbar(im, ax=ax)

                plot_with_download(fig2, "unmixing_abundance_maps.png", "üì• T·∫£i Abundance Maps")

            else:
                # 2D data
                fig2, axes = plt.subplots(1, len(abundance_maps), figsize=(4*len(abundance_maps), 4), dpi=150)
                if len(abundance_maps) == 1:
                    axes = [axes]

                for i, (amap, ax) in enumerate(zip(abundance_maps, axes)):
                    im = ax.imshow(amap, cmap='viridis')
                    ax.set_title(f"Endmember {i+1}")
                    plt.colorbar(im, ax=ax)

                plot_with_download(fig2, "unmixing_abundance_maps.png", "üì• T·∫£i Abundance Maps")

        except Exception as e:
            st.warning(f"Kh√¥ng th·ªÉ hi·ªÉn th·ªã abundance maps: {str(e)}")

    elif result_type == 'peaks':
        st.write("### K·∫øt qu·∫£ Peak Detection")

        all_peaks = results['all_peaks']
        mode = results.get('mode', 'Ph·ªï ƒë∆°n l·∫ª')

        # Single spectrum mode
        if mode == "Ph·ªï ƒë∆°n l·∫ª" or len(all_peaks) == 1:
            result = all_peaks[0]
            peaks = result['peaks']
            intensities = result['intensities']
            spectral_axis = result['spectral_axis']
            spectrum_name = result['name']

            fig, ax = plt.subplots(figsize=(12, 6), dpi=150)

            # Plot spectrum with name in legend
            ax.plot(spectral_axis, intensities, 'b-', linewidth=1.5, label=spectrum_name)
            ax.plot(spectral_axis[peaks], intensities[peaks], 'ro', markersize=8, label=f'Peaks ({len(peaks)})')

            # ƒê√°nh d·∫•u peaks
            for peak in peaks:
                ax.axvline(spectral_axis[peak], color='r', linestyle='--', alpha=0.3)
                ax.text(spectral_axis[peak], intensities[peak], f'{spectral_axis[peak]:.0f}',
                       rotation=45, ha='right', va='bottom', fontsize=8)

            ax.set_xlabel('Wavenumber (cm‚Åª¬π)')
            ax.set_ylabel('Intensity')
            ax.set_title(f'Peak Detection: {spectrum_name} - {len(peaks)} peaks')
            ax.legend()
            ax.grid(True, alpha=0.3)

            plot_with_download(fig, f"peak_detection_{spectrum_name}.png", "üì• T·∫£i Peak Detection")

            # B·∫£ng th√¥ng tin peaks
            st.write("#### üìã Danh s√°ch Peaks")
            peak_data = {
                'Peak #': range(1, len(peaks)+1),
                'Position (index)': peaks,
                'Wavenumber (cm‚Åª¬π)': [f"{spectral_axis[p]:.2f}" for p in peaks],
                'Intensity': [f"{intensities[p]:.4f}" for p in peaks]
            }

            import pandas as pd
            df = pd.DataFrame(peak_data)
            st.dataframe(df, use_container_width=True)

            # CSV Export for peak detection
            st.markdown("---")
            create_csv_download(df, f"peak_detection_{spectrum_name}.csv", "üì• T·∫£i Peak Detection CSV")

        # Compare all spectra mode
        else:
            st.info(f"üìä So s√°nh peaks c·ªßa {len(all_peaks)} ph·ªï")

            # Plot all spectra with peaks
            fig, ax = plt.subplots(figsize=(14, 8), dpi=150)

            # Color palette
            colors = plt.cm.tab10(np.linspace(0, 1, len(all_peaks)))

            for idx, result in enumerate(all_peaks):
                peaks = result['peaks']
                intensities = result['intensities']
                spectral_axis = result['spectral_axis']
                spectrum_name = result['name']
                color = colors[idx]

                # Plot spectrum
                ax.plot(spectral_axis, intensities, '-', linewidth=1.5,
                       color=color, label=f"{spectrum_name} ({len(peaks)} peaks)", alpha=0.7)

                # Plot peaks
                ax.plot(spectral_axis[peaks], intensities[peaks], 'o',
                       markersize=6, color=color)

            ax.set_xlabel('Wavenumber (cm‚Åª¬π)')
            ax.set_ylabel('Intensity')
            ax.set_title(f'Peak Detection - So s√°nh {len(all_peaks)} ph·ªï')
            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
            ax.grid(True, alpha=0.3)

            plot_with_download(fig, "peak_detection_comparison.png", "üì• T·∫£i Peak Comparison")

            # B·∫£ng th√¥ng tin t·ªïng h·ª£p
            st.write("#### üìã T·ªïng h·ª£p Peaks")

            # Create combined table
            all_peak_data = []
            for result in all_peaks:
                spectrum_name = result['name']
                peaks = result['peaks']
                intensities = result['intensities']
                spectral_axis = result['spectral_axis']

                for i, peak in enumerate(peaks):
                    all_peak_data.append({
                        'M·∫´u': spectrum_name,
                        'Peak #': i+1,
                        'Wavenumber (cm‚Åª¬π)': f"{spectral_axis[peak]:.2f}",
                        'Intensity': f"{intensities[peak]:.4f}"
                    })

            import pandas as pd
            df_all = pd.DataFrame(all_peak_data)
            st.dataframe(df_all, use_container_width=True)

            # CSV Export
            st.markdown("---")
            create_csv_download(df_all, "peak_detection_all_spectra.csv", "üì• T·∫£i t·∫•t c·∫£ Peaks CSV")

            # Summary statistics
            st.write("#### üìä Th·ªëng k√™")
            col_stat1, col_stat2, col_stat3 = st.columns(3)

            with col_stat1:
                total_peaks = sum(len(r['peaks']) for r in all_peaks)
                st.metric("T·ªïng s·ªë peaks", total_peaks)

            with col_stat2:
                avg_peaks = total_peaks / len(all_peaks)
                st.metric("Trung b√¨nh peaks/ph·ªï", f"{avg_peaks:.1f}")

            with col_stat3:
                st.metric("S·ªë ph·ªï", len(all_peaks))

    elif result_type == 'pca':
        st.write("### K·∫øt qu·∫£ PCA")

        scores = results['scores']
        loadings = results['loadings']
        explained_variance = results['explained_variance']
        spectrum_names = results.get('spectrum_names', [])
        n_components = results.get('n_components', len(loadings))

        # Gi·∫£i th√≠ch PCA
        with st.expander("‚ÑπÔ∏è PCA l√† g√¨? C√°ch ƒë·ªçc k·∫øt qu·∫£", expanded=False):
            st.markdown("""
            ### Principal Component Analysis (PCA)

            PCA gi√∫p **gi·∫£m chi·ªÅu d·ªØ li·ªáu** v√† t√¨m ra **s·ª± kh√°c bi·ªát ch√≠nh** gi·ªØa c√°c ph·ªï.

            #### üìä **Explained Variance (Scree Plot)**
            - Cho bi·∫øt m·ªói PC "gi·∫£i th√≠ch" bao nhi√™u % s·ª± bi·∫øn thi√™n trong d·ªØ li·ªáu
            - PC1 th∆∞·ªùng c√≥ % cao nh·∫•t (v√≠ d·ª•: 80%) ‚Üí quan tr·ªçng nh·∫•t
            - PC2, PC3, PC4... gi·∫£m d·∫ßn

            #### üéØ **Score Plot**
            - M·ªói ƒëi·ªÉm = 1 ph·ªï c·ªßa b·∫°n
            - Kho·∫£ng c√°ch gi·ªØa c√°c ƒëi·ªÉm = m·ª©c ƒë·ªô kh√°c bi·ªát gi·ªØa c√°c ph·ªï
            - ƒêi·ªÉm g·∫ßn nhau = ph·ªï t∆∞∆°ng t·ª±
            - ƒêi·ªÉm xa nhau = ph·ªï kh√°c bi·ªát

            #### üìà **Loading Plot**
            - Loading = "Ph·ªï ƒë·∫∑c tr∆∞ng" c·ªßa m·ªói PC
            - Peak cao trong loading plot = wavenumber quan tr·ªçng
            - Cho bi·∫øt **v√πng ph·ªï n√†o** ƒë√≥ng g√≥p v√†o s·ª± kh√°c bi·ªát gi·ªØa c√°c m·∫´u
            - V√≠ d·ª•: Peak cao ·ªü 1000 cm‚Åª¬π trong PC1 loading ‚Üí v√πng 1000 cm‚Åª¬π l√† ƒë·∫∑c tr∆∞ng ch√≠nh ph√¢n bi·ªát c√°c ph·ªï
            """)

        col1, col2 = st.columns(2)

        with col1:
            # Scree plot
            st.write("#### üìä Explained Variance")
            fig1, ax1 = plt.subplots(figsize=(6, 4), dpi=150)
            ax1.bar(range(1, len(explained_variance)+1), explained_variance * 100)
            ax1.set_xlabel('Principal Component')
            ax1.set_ylabel('Explained Variance (%)')
            ax1.set_title('Scree Plot')
            plot_with_download(fig1, "pca_scree_plot.png", "üì• T·∫£i Scree Plot")

        with col2:
            # Score plot v·ªõi m√†u s·∫Øc v√† legend
            st.write("#### üéØ Score Plot")

            # Dropdown ƒë·ªÉ ch·ªçn PC n√†o ƒë·ªÉ plot
            if n_components >= 2:
                col_x, col_y = st.columns(2)
                with col_x:
                    pc_x = st.selectbox("Tr·ª•c X:", [f"PC{i+1}" for i in range(n_components)], index=0, key="pc_x_select")
                    pc_x_idx = int(pc_x.replace("PC", "")) - 1
                with col_y:
                    pc_y = st.selectbox("Tr·ª•c Y:", [f"PC{i+1}" for i in range(n_components)], index=1, key="pc_y_select")
                    pc_y_idx = int(pc_y.replace("PC", "")) - 1

                fig2, ax2 = plt.subplots(figsize=(6, 4), dpi=150)

                # S·ªë ph·ªï
                n_spectra = len(scores)
                colors = plt.cm.tab10(np.linspace(0, 1, n_spectra))

                # Plot t·ª´ng ƒëi·ªÉm v·ªõi m√†u ri√™ng
                for i in range(n_spectra):
                    label = spectrum_names[i] if i < len(spectrum_names) else f'Ph·ªï {i+1}'
                    ax2.scatter(scores[i, pc_x_idx], scores[i, pc_y_idx],
                               color=colors[i], s=100, alpha=0.8,
                               edgecolors='black', linewidth=1,
                               label=label)

                ax2.set_xlabel(f'{pc_x} ({explained_variance[pc_x_idx]*100:.1f}%)')
                ax2.set_ylabel(f'{pc_y} ({explained_variance[pc_y_idx]*100:.1f}%)')
                ax2.set_title(f'Score Plot: {pc_x} vs {pc_y}')
                ax2.legend(loc='best', fontsize=9, framealpha=0.9)
                ax2.grid(True, alpha=0.3)
                plot_with_download(fig2, f"pca_score_{pc_x}_vs_{pc_y}.png", "üì• T·∫£i Score Plot")
            else:
                st.warning("C·∫ßn √≠t nh·∫•t 2 components ƒë·ªÉ plot Score Plot")

        # Score plot matrix (t·∫•t c·∫£ c√°c c·∫∑p PC)
        if n_components >= 3:
            st.markdown("---")
            show_matrix = st.checkbox("üìä Hi·ªÉn th·ªã Score Plot Matrix (t·∫•t c·∫£ c√°c c·∫∑p PC)", value=False)

            if show_matrix:
                st.write("### üéØ Score Plot Matrix")
                st.info("Ma tr·∫≠n n√†y hi·ªÉn th·ªã t·∫•t c·∫£ c√°c c·∫∑p PC c√≥ th·ªÉ. M·ªói √¥ = 1 score plot v·ªõi 2 PC kh√°c nhau.")

                # T√≠nh s·ªë plots
                n_plots = min(4, n_components)  # T·ªëi ƒëa 4 PCs ƒë·ªÉ kh√¥ng qu√° nhi·ªÅu plots
                fig_matrix, axes_matrix = plt.subplots(n_plots-1, n_plots-1, figsize=(4*(n_plots-1), 4*(n_plots-1)), dpi=150)

                n_spectra = len(scores)
                colors = plt.cm.tab10(np.linspace(0, 1, n_spectra))

                for i in range(n_plots-1):
                    for j in range(n_plots-1):
                        if j > i:
                            # Upper triangle - hide
                            if n_plots > 2:
                                axes_matrix[i, j].set_visible(False)
                        else:
                            # Lower triangle - plot
                            ax = axes_matrix[i, j] if n_plots > 2 else axes_matrix[i] if n_plots == 2 and j == 0 else axes_matrix

                            # PC indices: x = j+1, y = i+2
                            pc_x_idx = j
                            pc_y_idx = i + 1

                            # Plot each spectrum
                            for k in range(n_spectra):
                                label = spectrum_names[k] if k < len(spectrum_names) else f'Ph·ªï {k+1}'
                                ax.scatter(scores[k, pc_x_idx], scores[k, pc_y_idx],
                                          color=colors[k], s=60, alpha=0.8,
                                          edgecolors='black', linewidth=0.5,
                                          label=label if i == 0 and j == 0 else "")

                            ax.set_xlabel(f'PC{pc_x_idx+1} ({explained_variance[pc_x_idx]*100:.1f}%)', fontsize=9)
                            ax.set_ylabel(f'PC{pc_y_idx+1} ({explained_variance[pc_y_idx]*100:.1f}%)', fontsize=9)
                            ax.grid(True, alpha=0.3)

                            # Legend ch·ªâ ·ªü plot ƒë·∫ßu ti√™n
                            if i == 0 and j == 0:
                                ax.legend(loc='best', fontsize=7, framealpha=0.9)

                plt.tight_layout()
                plot_with_download(fig_matrix, "pca_score_matrix.png", "üì• T·∫£i Score Matrix")

        # Loading plot - hi·ªÉn th·ªã T·∫§T C·∫¢ components
        st.markdown("---")
        st.write(f"#### üìà Loading Plots (t·∫•t c·∫£ {n_components} components)")
        st.info("üí° Loading plot cho bi·∫øt wavenumber n√†o quan tr·ªçng trong m·ªói PC. Peak cao = v√πng ph·ªï ƒë·∫∑c tr∆∞ng.")

        # T√≠nh s·ªë h√†ng v√† c·ªôt cho subplot
        n_cols = min(3, n_components)  # T·ªëi ƒëa 3 c·ªôt
        n_rows = (n_components + n_cols - 1) // n_cols  # L√†m tr√≤n l√™n

        fig3, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 4*n_rows), dpi=150)

        # Flatten axes ƒë·ªÉ d·ªÖ iterate
        if n_components == 1:
            axes = [axes]
        elif n_rows == 1 or n_cols == 1:
            axes = axes.flatten()
        else:
            axes = axes.flatten()

        for i in range(n_components):
            ax = axes[i]
            ax.plot(loadings[i], linewidth=1.5, color=plt.cm.tab10(i/10))
            ax.set_title(f'PC{i+1} Loading ({explained_variance[i]*100:.1f}%)', fontweight='bold')
            ax.set_xlabel('Wavenumber index')
            ax.set_ylabel('Loading')
            ax.grid(True, alpha=0.3)

        # ·∫®n c√°c subplot tr·ªëng n·∫øu c√≥
        for i in range(n_components, len(axes)):
            axes[i].set_visible(False)

        plt.tight_layout()
        plot_with_download(fig3, "pca_loadings.png", "üì• T·∫£i Loading Plots")

        # CSV Export cho PCA
        st.markdown("---")
        st.write("### üì• T·∫£i d·ªØ li·ªáu PCA")

        col_csv1, col_csv2, col_csv3 = st.columns(3)

        with col_csv1:
            st.write("**Scores**")
            # T·∫°o DataFrame cho scores
            score_columns = [f'PC{i+1}' for i in range(n_components)]
            score_labels = [spectrum_names[i] if i < len(spectrum_names) else f'Ph·ªï {i+1}' for i in range(len(scores))]
            scores_df = pd.DataFrame(scores, columns=score_columns, index=score_labels)
            scores_df.insert(0, 'Spectrum', score_labels)
            create_csv_download(scores_df, "pca_scores.csv", "üì• T·∫£i Scores CSV")

        with col_csv2:
            st.write("**Loadings**")
            # T·∫°o DataFrame cho loadings
            loading_columns = [f'Feature_{i+1}' for i in range(loadings.shape[1])]
            loading_labels = [f'PC{i+1}' for i in range(n_components)]
            loadings_df = pd.DataFrame(loadings, columns=loading_columns, index=loading_labels)
            loadings_df.insert(0, 'Component', loading_labels)
            create_csv_download(loadings_df, "pca_loadings.csv", "üì• T·∫£i Loadings CSV")

        with col_csv3:
            st.write("**Explained Variance**")
            # T·∫°o DataFrame cho explained variance
            var_df = pd.DataFrame({
                'Component': [f'PC{i+1}' for i in range(len(explained_variance))],
                'Explained Variance (%)': explained_variance * 100,
                'Cumulative (%)': np.cumsum(explained_variance) * 100
            })
            create_csv_download(var_df, "pca_explained_variance.csv", "üì• T·∫£i Variance CSV")

# Footer
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: gray;'>
    <p>RamanSPy GUI v1.0 | ƒê∆∞·ª£c x√¢y d·ª±ng v·ªõi Streamlit</p>
    <p>T√†i li·ªáu: <a href='https://ramanspy.readthedocs.io'>ramanspy.readthedocs.io</a></p>
</div>
""", unsafe_allow_html=True)
