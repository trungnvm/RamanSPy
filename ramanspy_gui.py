"""
RamanSPy GUI - Giao di·ªán ƒë·ªì h·ªça cho ph√¢n t√≠ch ph·ªï Raman
Ch·∫°y ·ª©ng d·ª•ng: streamlit run ramanspy_gui.py
"""

import streamlit as st
import ramanspy as rp
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import tempfile
import os

# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="RamanSPy GUI",
    page_icon="üî¨",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS t√πy ch·ªânh
st.markdown("""
    <style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.5rem;
        font-weight: bold;
        color: #2ca02c;
        margin-top: 2rem;
        margin-bottom: 1rem;
    }
    </style>
""", unsafe_allow_html=True)

# Header
st.markdown('<p class="main-header">üî¨ RamanSPy - Ph√¢n t√≠ch ph·ªï Raman</p>', unsafe_allow_html=True)

# Kh·ªüi t·∫°o session state
if 'data' not in st.session_state:
    st.session_state.data = None
if 'preprocessed_data' not in st.session_state:
    st.session_state.preprocessed_data = None
if 'pipeline_steps' not in st.session_state:
    st.session_state.pipeline_steps = []
if 'analysis_results' not in st.session_state:
    st.session_state.analysis_results = None
if 'spectra_collection' not in st.session_state:
    st.session_state.spectra_collection = []  # List of {'name': str, 'data': Spectrum, 'preprocessed': None}

# Sidebar - Navigation
st.sidebar.title("üìã Menu")
page = st.sidebar.radio(
    "Ch·ªçn ch·ª©c nƒÉng:",
    ["T·∫£i d·ªØ li·ªáu", "Ti·ªÅn x·ª≠ l√Ω", "Ph√¢n t√≠ch", "Tr·ª±c quan h√≥a"]
)

st.sidebar.markdown("---")
st.sidebar.info("""
**RamanSPy GUI v1.0**

C√¥ng c·ª• ph√¢n t√≠ch ph·ªï Raman ƒë∆°n gi·∫£n v√† d·ªÖ s·ª≠ d·ª•ng.

[T√†i li·ªáu](https://ramanspy.readthedocs.io)
""")

# ==================== TRANG T·∫¢I D·ªÆ LI·ªÜU ====================
if page == "T·∫£i d·ªØ li·ªáu":
    st.markdown('<p class="sub-header">üìÇ T·∫£i d·ªØ li·ªáu ph·ªï Raman</p>', unsafe_allow_html=True)

    tab1, tab2, tab3 = st.tabs(["üìÅ T·∫£i t·ª´ file", "üìä D·ªØ li·ªáu m·∫´u", "üé≤ D·ªØ li·ªáu t·ªïng h·ª£p"])

    # Tab 1: T·∫£i t·ª´ file
    with tab1:
        st.write("### T·∫£i d·ªØ li·ªáu t·ª´ file")

        col1, col2 = st.columns([2, 1])

        with col1:
            file_format = st.selectbox(
                "Ch·ªçn ƒë·ªãnh d·∫°ng file:",
                ["CSV/Text (t√πy ch·ªânh)", "WITec", "Renishaw", "NumPy (.npy)"]
            )

        with col2:
            st.info("üí° Ch·ªçn ƒë√∫ng ƒë·ªãnh d·∫°ng c·ªßa thi·∫øt b·ªã ƒëo")

        # H∆∞·ªõng d·∫´n cho CSV/Text
        if file_format == "CSV/Text (t√πy ch·ªânh)":
            with st.expander("‚ÑπÔ∏è ƒê·ªãnh d·∫°ng CSV/Text ƒë∆∞·ª£c h·ªó tr·ª£"):
                st.write("""
                **ƒê·ªãnh d·∫°ng file ƒë∆∞·ª£c h·ªó tr·ª£:**
                - Header (t√πy ch·ªçn) v·ªõi metadata
                - D·ªØ li·ªáu 2 c·ªôt: Wavenumber v√† Intensity
                - Ph√¢n c√°ch b·∫±ng: `;` , `,` , tab ho·∫∑c kho·∫£ng tr·∫Øng

                **V√≠ d·ª•:**
                ```
                Name=Andor Spectra
                X=Raman Shift, 1/cm
                Y=Intensity, Counts
                2.37; 2405
                6.04; 2446
                9.70; 2369
                ...
                ```
                """)

        uploaded_files = st.file_uploader(
            "Ch·ªçn file d·ªØ li·ªáu:",
            type=['txt', 'csv', 'wdf', 'npy', 'npz', 'dat'],
            help="H·ªó tr·ª£ nhi·ªÅu ƒë·ªãnh d·∫°ng file t·ª´ c√°c thi·∫øt b·ªã Raman kh√°c nhau",
            accept_multiple_files=True
        )

        # Checkbox ƒë·ªÉ t·ª± ƒë·ªông th√™m v√†o collection
        auto_add_to_collection = st.checkbox(
            "T·ª± ƒë·ªông th√™m v√†o Collection sau khi t·∫£i",
            value=True,
            help="T·ª± ƒë·ªông th√™m c√°c file ƒë√£ t·∫£i v√†o collection ƒë·ªÉ d·ªÖ qu·∫£n l√Ω"
        )

        if uploaded_files:
            loaded_count = 0
            failed_files = []

            for uploaded_file in uploaded_files:
                try:
                    # L∆∞u file t·∫°m
                    with tempfile.NamedTemporaryFile(delete=False, suffix=Path(uploaded_file.name).suffix) as tmp_file:
                        tmp_file.write(uploaded_file.getvalue())
                        tmp_path = tmp_file.name

                    with st.spinner(f"ƒêang t·∫£i {uploaded_file.name}..."):
                        # Load d·ªØ li·ªáu theo ƒë·ªãnh d·∫°ng
                        if file_format == "WITec":
                            loaded_data = rp.load.witec(tmp_path)
                        elif file_format == "Renishaw":
                            loaded_data = rp.load.renishaw(tmp_path)
                        elif file_format == "NumPy (.npy)":
                            data_array = np.load(tmp_path)
                            loaded_data = rp.Spectrum(data_array)
                        else:
                            # CSV/Text (t√πy ch·ªânh)
                            with open(tmp_path, 'r', encoding='utf-8') as f:
                                lines = f.readlines()

                            # T√¨m d√≤ng b·∫Øt ƒë·∫ßu d·ªØ li·ªáu
                            data_start = 0
                            for i, line in enumerate(lines):
                                if line.strip() and (line.strip()[0].isdigit() or line.strip()[0] == '-'):
                                    data_start = i
                                    break

                            # Parse d·ªØ li·ªáu
                            wavenumbers = []
                            intensities = []

                            for line in lines[data_start:]:
                                line = line.strip()
                                if not line:
                                    continue

                                # Th·ª≠ c√°c delimiter kh√°c nhau
                                if ';' in line:
                                    parts = line.split(';')
                                elif ',' in line:
                                    parts = line.split(',')
                                elif '\t' in line:
                                    parts = line.split('\t')
                                else:
                                    parts = line.split()

                                if len(parts) >= 2:
                                    try:
                                        wavenumbers.append(float(parts[0].strip()))
                                        intensities.append(float(parts[1].strip()))
                                    except ValueError:
                                        continue

                            # T·∫°o Spectrum object
                            if len(wavenumbers) > 0 and len(intensities) > 0:
                                loaded_data = rp.Spectrum(
                                    np.array(intensities),
                                    spectral_axis=np.array(wavenumbers)
                                )
                            else:
                                raise ValueError("Kh√¥ng th·ªÉ ƒë·ªçc d·ªØ li·ªáu t·ª´ file.")

                    os.unlink(tmp_path)

                    # L∆∞u v√†o st.session_state.data (file cu·ªëi c√πng)
                    st.session_state.data = loaded_data

                    # T·ª± ƒë·ªông th√™m v√†o collection n·∫øu ƒë∆∞·ª£c ch·ªçn
                    if auto_add_to_collection:
                        # L·∫•y t√™n file (kh√¥ng c√≥ extension)
                        file_base_name = Path(uploaded_file.name).stem

                        # Ki·ªÉm tra tr√πng t√™n
                        existing_names = [s['name'] for s in st.session_state.spectra_collection]
                        final_name = file_base_name
                        counter = 1
                        while final_name in existing_names:
                            final_name = f"{file_base_name}_{counter}"
                            counter += 1

                        st.session_state.spectra_collection.append({
                            'name': final_name,
                            'original_filename': uploaded_file.name,
                            'data': loaded_data,
                            'preprocessed': None,
                            'selected': True
                        })

                    loaded_count += 1

                except Exception as e:
                    failed_files.append((uploaded_file.name, str(e)))

            # Hi·ªÉn th·ªã k·∫øt qu·∫£
            if loaded_count > 0:
                st.success(f"‚úÖ ƒê√£ t·∫£i th√†nh c√¥ng {loaded_count} file(s)")
                if auto_add_to_collection:
                    st.info(f"üí° ƒê√£ th√™m {loaded_count} ph·ªï v√†o Collection. M·ªü r·ªông 'üìö Qu·∫£n l√Ω Collection Ph·ªï' ƒë·ªÉ xem.")

            if failed_files:
                st.error(f"‚ùå L·ªói khi t·∫£i {len(failed_files)} file(s):")
                for fname, error in failed_files:
                    st.write(f"- {fname}: {error}")

            # Hi·ªÉn th·ªã th√¥ng tin ph·ªï cu·ªëi c√πng ƒë∆∞·ª£c load
            if st.session_state.data is not None and loaded_count > 0:
                st.write("### Th√¥ng tin ph·ªï cu·ªëi c√πng ƒë∆∞·ª£c t·∫£i")
                col1, col2, col3 = st.columns(3)

                with col1:
                    st.metric("Ki·ªÉu d·ªØ li·ªáu", type(st.session_state.data).__name__)
                with col2:
                    st.metric("K√≠ch th∆∞·ªõc", str(st.session_state.data.shape))
                with col3:
                    if hasattr(st.session_state.data, 'spectral_axis'):
                        st.metric("S·ªë ƒëi·ªÉm ph·ªï", len(st.session_state.data.spectral_axis))

    # Tab 2: D·ªØ li·ªáu m·∫´u
    with tab2:
        st.write("### T·∫£i d·ªØ li·ªáu m·∫´u t·ª´ RamanSPy")

        st.info("üì• D·ªØ li·ªáu s·∫Ω ƒë∆∞·ª£c t·∫£i xu·ªëng t·ª± ƒë·ªông t·ª´ repository")

        dataset_type = st.selectbox(
            "Ch·ªçn lo·∫°i d·ªØ li·ªáu:",
            ["THP-1 cells", "MCF-7 cells", "Bacteria dataset"]
        )

        col1, col2 = st.columns([1, 3])

        with col1:
            if st.button("üì• T·∫£i d·ªØ li·ªáu m·∫´u", type="primary"):
                try:
                    with st.spinner("ƒêang t·∫£i d·ªØ li·ªáu m·∫´u..."):
                        data_dir = "./data/kallepitis_data"

                        # Ch·ªçn cell type
                        if dataset_type == "THP-1 cells":
                            cell_type = 'THP-1'
                        elif dataset_type == "MCF-7 cells":
                            cell_type = 'MCF-7'
                        else:
                            cell_type = 'THP-1'

                        volumes = rp.datasets.volumetric_cells(cell_type=cell_type, folder=data_dir)
                        st.session_state.data = volumes[0]

                        st.success(f"‚úÖ ƒê√£ t·∫£i d·ªØ li·ªáu m·∫´u: {dataset_type}")
                        st.rerun()

                except Exception as e:
                    st.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ t·∫£i d·ªØ li·ªáu m·∫´u: {str(e)}")
                    st.info("D·ªØ li·ªáu m·∫´u c·∫ßn ƒë∆∞·ª£c t·∫£i v·ªÅ tr∆∞·ªõc. B·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng d·ªØ li·ªáu t·ªïng h·ª£p ƒë·ªÉ th·ª≠ nghi·ªám.")

        with col2:
            if dataset_type == "THP-1 cells":
                st.write("**THP-1 cells**: D·ªØ li·ªáu ph·ªï Raman 3D c·ªßa t·∫ø b√†o THP-1")
            elif dataset_type == "MCF-7 cells":
                st.write("**MCF-7 cells**: D·ªØ li·ªáu ph·ªï Raman 3D c·ªßa t·∫ø b√†o MCF-7")

    # Tab 3: D·ªØ li·ªáu t·ªïng h·ª£p
    with tab3:
        st.write("### T·∫°o d·ªØ li·ªáu t·ªïng h·ª£p ƒë·ªÉ th·ª≠ nghi·ªám")

        col1, col2 = st.columns(2)

        with col1:
            n_spectra = st.slider("S·ªë ph·ªï:", 10, 1000, 100)
            n_points = st.slider("S·ªë ƒëi·ªÉm ph·ªï:", 100, 2000, 500)

        with col2:
            noise_level = st.slider("M·ª©c nhi·ªÖu:", 0.0, 0.5, 0.1, 0.05)
            n_peaks = st.slider("S·ªë peak:", 1, 10, 3)

        if st.button("üé≤ T·∫°o d·ªØ li·ªáu t·ªïng h·ª£p", type="primary"):
            with st.spinner("ƒêang t·∫°o d·ªØ li·ªáu..."):
                # T·∫°o tr·ª•c wavenumber
                wavenumbers = np.linspace(400, 2000, n_points)

                # T·∫°o ph·ªï v·ªõi nhi·ªÅu peaks
                spectra_list = []
                for _ in range(n_spectra):
                    spectrum = np.zeros(n_points)

                    # Th√™m peaks ng·∫´u nhi√™n
                    for _ in range(n_peaks):
                        center = np.random.uniform(600, 1800)
                        width = np.random.uniform(20, 80)
                        height = np.random.uniform(0.5, 1.0)

                        # Gaussian peak
                        spectrum += height * np.exp(-((wavenumbers - center) ** 2) / (2 * width ** 2))

                    # Th√™m baseline
                    baseline = np.random.uniform(0.1, 0.3) * np.ones(n_points)
                    spectrum += baseline

                    # Th√™m nhi·ªÖu
                    noise = np.random.normal(0, noise_level, n_points)
                    spectrum += noise

                    spectra_list.append(spectrum)

                # T·∫°o SpectralContainer
                data_array = np.array(spectra_list)
                st.session_state.data = rp.SpectralContainer(data_array, spectral_axis=wavenumbers)

                st.success(f"‚úÖ ƒê√£ t·∫°o {n_spectra} ph·ªï t·ªïng h·ª£p v·ªõi {n_points} ƒëi·ªÉm")

    # ==================== QU·∫¢N L√ù NHI·ªÄU PH·ªî ====================
    st.markdown("---")
    with st.expander("üìö Qu·∫£n l√Ω Collection Ph·ªï (ƒë·ªÉ ch·∫°y PCA v·ªõi nhi·ªÅu ph·ªï)", expanded=False):
        st.write("### Th√™m ph·ªï hi·ªán t·∫°i v√†o collection")

        col_name, col_add = st.columns([3, 1])

        with col_name:
            spectrum_name = st.text_input(
                "T√™n ph·ªï:",
                value=f"Spectrum_{len(st.session_state.spectra_collection)+1}",
                help="ƒê·∫∑t t√™n ƒë·ªÉ d·ªÖ qu·∫£n l√Ω"
            )

        with col_add:
            st.write("")  # Spacing
            st.write("")  # Spacing
            if st.button("‚ûï Th√™m v√†o Collection"):
                if st.session_state.data is not None:
                    # Ki·ªÉm tra tr√πng t√™n
                    existing_names = [s['name'] for s in st.session_state.spectra_collection]
                    if spectrum_name in existing_names:
                        st.error(f"‚ùå T√™n '{spectrum_name}' ƒë√£ t·ªìn t·∫°i!")
                    else:
                        st.session_state.spectra_collection.append({
                            'name': spectrum_name,
                            'data': st.session_state.data,
                            'preprocessed': st.session_state.preprocessed_data,
                            'selected': True
                        })
                        st.success(f"‚úÖ ƒê√£ th√™m '{spectrum_name}' v√†o collection!")
                        st.rerun()
                else:
                    st.warning("‚ö†Ô∏è Ch∆∞a c√≥ d·ªØ li·ªáu ƒë·ªÉ th√™m. Vui l√≤ng t·∫£i file tr∆∞·ªõc!")

        # Hi·ªÉn th·ªã collection
        if len(st.session_state.spectra_collection) > 0:
            st.write(f"### üìã Collection ({len(st.session_state.spectra_collection)} ph·ªï)")

            # Selection mode
            col_mode1, col_mode2 = st.columns(2)
            with col_mode1:
                if st.button("‚úÖ Ch·ªçn t·∫•t c·∫£"):
                    for spec in st.session_state.spectra_collection:
                        spec['selected'] = True
                    st.rerun()
            with col_mode2:
                if st.button("‚òê B·ªè ch·ªçn t·∫•t c·∫£"):
                    for spec in st.session_state.spectra_collection:
                        spec['selected'] = False
                    st.rerun()

            # List spectra v·ªõi rename
            for i, spec in enumerate(st.session_state.spectra_collection):
                col1, col2, col3, col4, col5 = st.columns([0.5, 2, 2, 0.6, 0.6])

                with col1:
                    new_selected = st.checkbox(
                        "‚òë",
                        value=spec['selected'],
                        key=f"select_{i}",
                        label_visibility="collapsed"
                    )
                    if new_selected != spec['selected']:
                        spec['selected'] = new_selected

                with col2:
                    # Hi·ªÉn th·ªã t√™n file g·ªëc n·∫øu c√≥
                    original_name = spec.get('original_filename', '')
                    if original_name:
                        st.write(f"üìÑ `{original_name}`")
                    else:
                        st.write(f"Ph·ªï #{i+1}")

                with col3:
                    # Editable name
                    new_name = st.text_input(
                        "T√™n:",
                        value=spec['name'],
                        key=f"name_{i}",
                        label_visibility="collapsed",
                        placeholder="ƒê·∫∑t t√™n..."
                    )
                    if new_name != spec['name'] and new_name.strip():
                        # Check duplicate
                        existing = [s['name'] for idx, s in enumerate(st.session_state.spectra_collection) if idx != i]
                        if new_name not in existing:
                            spec['name'] = new_name

                    # Status
                    data_shape = spec['data'].shape if hasattr(spec['data'], 'shape') else "N/A"
                    preprocessed_status = "‚úÖ" if spec['preprocessed'] is not None else "‚ö™"
                    st.caption(f"{preprocessed_status} {data_shape}")

                with col4:
                    if st.button("üóëÔ∏è", key=f"del_{i}", help="X√≥a"):
                        st.session_state.spectra_collection.pop(i)
                        st.rerun()

                with col5:
                    if st.button("üëÅÔ∏è", key=f"view_{i}", help="Load"):
                        st.session_state.data = spec['data']
                        st.session_state.preprocessed_data = spec['preprocessed']
                        st.success(f"ƒê√£ load '{spec['name']}'")
                        st.rerun()

            # Actions
            st.markdown("---")
            selected_count = sum(1 for s in st.session_state.spectra_collection if s['selected'])
            st.info(f"**ƒê√£ ch·ªçn:** {selected_count} ph·ªï")

            if selected_count > 0:
                col_action1, col_action2 = st.columns(2)

                with col_action1:
                    # Batch preprocessing
                    if st.button("‚öôÔ∏è Ti·ªÅn x·ª≠ l√Ω h√†ng lo·∫°t", use_container_width=True, help="√Åp d·ª•ng pipeline cho c√°c ph·ªï ƒë√£ ch·ªçn"):
                        # Chuy·ªÉn sang tab preprocessing v·ªõi flag
                        st.session_state['batch_preprocess_mode'] = True
                        st.info("üí° Chuy·ªÉn sang tab 'Ti·ªÅn x·ª≠ l√Ω', thi·∫øt l·∫≠p pipeline, v√† click '√Åp d·ª•ng cho Collection'")

                with col_action2:
                    # Combine spectra
                    if selected_count > 1:
                        if st.button("üîó K·∫øt h·ª£p ƒë·ªÉ ch·∫°y PCA", type="primary", use_container_width=True):
                            # Get selected items
                            selected_items = [s for s in st.session_state.spectra_collection if s['selected']]

                            try:
                                # ∆Øu ti√™n d√πng preprocessed data n·∫øu c√≥
                                spectra_arrays = []
                                using_preprocessed = False

                                for item in selected_items:
                                    # D√πng preprocessed n·∫øu c√≥, kh√¥ng th√¨ d√πng raw
                                    spec = item['preprocessed'] if item['preprocessed'] is not None else item['data']

                                    if item['preprocessed'] is not None:
                                        using_preprocessed = True

                                    if hasattr(spec, 'spectral_data'):
                                        spectra_arrays.append(spec.spectral_data)
                                    else:
                                        spectra_arrays.append(np.array(spec))

                                combined_array = np.stack(spectra_arrays)

                                # Get common spectral axis
                                first_spec = selected_items[0]['preprocessed'] if selected_items[0]['preprocessed'] is not None else selected_items[0]['data']
                                if hasattr(first_spec, 'spectral_axis'):
                                    spectral_axis = first_spec.spectral_axis
                                else:
                                    spectral_axis = np.arange(combined_array.shape[-1])

                                # Create SpectralContainer
                                st.session_state.data = rp.SpectralContainer(combined_array, spectral_axis=spectral_axis)
                                st.session_state.preprocessed_data = None

                                if using_preprocessed:
                                    st.success(f"‚úÖ ƒê√£ k·∫øt h·ª£p {selected_count} ph·ªï (s·ª≠ d·ª•ng d·ªØ li·ªáu ƒë√£ ti·ªÅn x·ª≠ l√Ω)!")
                                else:
                                    st.success(f"‚úÖ ƒê√£ k·∫øt h·ª£p {selected_count} ph·ªï (d·ªØ li·ªáu g·ªëc)!")
                                    st.warning("‚ö†Ô∏è M·ªôt s·ªë ph·ªï ch∆∞a ƒë∆∞·ª£c ti·ªÅn x·ª≠ l√Ω. Khuy·∫øn ngh·ªã ti·ªÅn x·ª≠ l√Ω tr∆∞·ªõc khi ph√¢n t√≠ch.")

                                st.info("üí° Chuy·ªÉn sang tab 'Ph√¢n t√≠ch' ƒë·ªÉ ch·∫°y PCA.")
                                st.rerun()

                            except Exception as e:
                                st.error(f"‚ùå L·ªói khi k·∫øt h·ª£p ph·ªï: {str(e)}")
                    else:
                        st.info("üí° Ch·ªçn √≠t nh·∫•t 2 ph·ªï ƒë·ªÉ k·∫øt h·ª£p v√† ch·∫°y PCA.")

            elif selected_count == 1:
                st.info("üí° Ch·ªâ ch·ªçn 1 ph·ªï. S·ª≠ d·ª•ng Peak Detection ƒë·ªÉ ph√¢n t√≠ch ph·ªï ƒë∆°n.")
        else:
            st.info("Collection tr·ªëng. T·∫£i file v√† ch·ªçn 'T·ª± ƒë·ªông th√™m v√†o Collection' khi upload.")

    # Preview d·ªØ li·ªáu n·∫øu ƒë√£ load
    if st.session_state.data is not None:
        st.markdown("---")
        st.write("### üëÄ Preview d·ªØ li·ªáu")

        try:
            # L·∫•y m·ªôt v√†i ph·ªï ƒë·ªÉ hi·ªÉn th·ªã
            data_type = type(st.session_state.data).__name__

            if data_type == 'Spectrum':
                # Spectrum ƒë∆°n l·∫ª
                sample_spectra = st.session_state.data
            elif hasattr(st.session_state.data, 'flat'):
                # Volumetric data
                sample_spectra = st.session_state.data.flat[0:5]
            elif hasattr(st.session_state.data, '__len__') and len(st.session_state.data.shape) > 1:
                sample_spectra = st.session_state.data[0:5]
            else:
                sample_spectra = st.session_state.data

            # Plot
            fig, ax = plt.subplots(figsize=(10, 4))
            rp.plot.spectra(sample_spectra, ax=ax, plot_type='single')
            ax.set_title("Preview ph·ªï Raman")
            ax.set_xlabel("Wavenumber (cm‚Åª¬π)")
            ax.set_ylabel("Intensity")
            ax.grid(True, alpha=0.3)
            st.pyplot(fig)
            plt.close()

        except Exception as e:
            st.error(f"Kh√¥ng th·ªÉ hi·ªÉn th·ªã preview: {str(e)}")

# ==================== TRANG TI·ªÄN X·ª¨ L√ù ====================
elif page == "Ti·ªÅn x·ª≠ l√Ω":
    st.markdown('<p class="sub-header">‚öôÔ∏è Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu</p>', unsafe_allow_html=True)

    if st.session_state.data is None:
        st.warning("‚ö†Ô∏è Vui l√≤ng t·∫£i d·ªØ li·ªáu tr∆∞·ªõc!")
        st.stop()

    st.write("### X√¢y d·ª±ng Pipeline ti·ªÅn x·ª≠ l√Ω")

    # Sidebar cho vi·ªác ch·ªçn c√°c b∆∞·ªõc preprocessing
    st.write("#### Ch·ªçn c√°c b∆∞·ªõc ti·ªÅn x·ª≠ l√Ω:")

    col1, col2 = st.columns([1, 1])

    with col1:
        st.write("**B∆∞·ªõc 1: C·∫Øt v√πng ph·ªï (Cropping)**")
        use_cropping = st.checkbox("S·ª≠ d·ª•ng Cropping", value=True)
        if use_cropping:
            crop_min = st.number_input("Wavenumber min (cm‚Åª¬π):", 400, 2000, 700, 50)
            crop_max = st.number_input("Wavenumber max (cm‚Åª¬π):", 400, 2000, 1800, 50)

    with col2:
        st.write("**B∆∞·ªõc 2: Lo·∫°i b·ªè Cosmic Ray**")
        use_despike = st.checkbox("S·ª≠ d·ª•ng Despike", value=True)
        if use_despike:
            st.write("Ph∆∞∆°ng ph√°p: **WhitakerHayes**")
            with st.expander("‚öôÔ∏è T√πy ch·ªânh parameters"):
                despike_kernel = st.slider("Kernel size:", 1, 9, 3, 2, help="K√≠ch th∆∞·ªõc kernel ƒë·ªÉ detect spikes")
                despike_threshold = st.slider("Threshold:", 1.0, 20.0, 8.0, 1.0, help="Ng∆∞·ª°ng ƒë·ªÉ x√°c ƒë·ªãnh spike")

    col3, col4 = st.columns([1, 1])

    with col3:
        st.write("**B∆∞·ªõc 3: Kh·ª≠ nhi·ªÖu (Denoising)**")
        use_denoise = st.checkbox("S·ª≠ d·ª•ng Denoising", value=True)
        if use_denoise:
            denoise_method = st.selectbox(
                "Ph∆∞∆°ng ph√°p kh·ª≠ nhi·ªÖu:",
                ["SavGol", "Gaussian", "Wavelet"]
            )

            if denoise_method == "SavGol":
                window_length = st.slider("Window length:", 3, 21, 9, 2)
                polyorder = st.slider("Polynomial order:", 1, 5, 3)
            elif denoise_method == "Gaussian":
                sigma = st.slider("Sigma:", 0.5, 5.0, 1.0, 0.5)

    with col4:
        st.write("**B∆∞·ªõc 4: Hi·ªáu ch·ªânh Baseline**")
        use_baseline = st.checkbox("S·ª≠ d·ª•ng Baseline Correction", value=True)
        if use_baseline:
            baseline_method = st.selectbox(
                "Ph∆∞∆°ng ph√°p baseline:",
                ["ASPLS", "ASLS", "Poly"]
            )

            if baseline_method == "Poly":
                poly_order = st.slider("Polynomial order:", 1, 5, 3)

    col5, col6 = st.columns([1, 1])

    with col5:
        st.write("**B∆∞·ªõc 5: Chu·∫©n h√≥a (Normalization)**")
        use_normalize = st.checkbox("S·ª≠ d·ª•ng Normalization", value=True)
        if use_normalize:
            normalize_method = st.selectbox(
                "Ph∆∞∆°ng ph√°p chu·∫©n h√≥a:",
                ["MinMax", "AUC", "Vector", "SNV"]
            )

    # N√∫t √°p d·ª•ng pipeline
    st.markdown("---")
    col_btn1, col_btn2, col_btn3 = st.columns([1, 1, 1])

    with col_btn1:
        if st.button("‚ñ∂Ô∏è √Åp d·ª•ng Pipeline", type="primary", use_container_width=True):
            try:
                with st.spinner("ƒêang x·ª≠ l√Ω..."):
                    # X√¢y d·ª±ng pipeline
                    steps = []

                    if use_cropping:
                        steps.append(rp.preprocessing.misc.Cropper(region=(crop_min, crop_max)))

                    if use_despike:
                        steps.append(rp.preprocessing.despike.WhitakerHayes(
                            kernel_size=despike_kernel,
                            threshold=despike_threshold
                        ))

                    if use_denoise:
                        if denoise_method == "SavGol":
                            steps.append(rp.preprocessing.denoise.SavGol(window_length=window_length, polyorder=polyorder))
                        elif denoise_method == "Gaussian":
                            steps.append(rp.preprocessing.denoise.Gaussian(sigma=sigma))
                        else:
                            steps.append(rp.preprocessing.denoise.Wavelet())

                    if use_baseline:
                        if baseline_method == "ASPLS":
                            steps.append(rp.preprocessing.baseline.ASPLS())
                        elif baseline_method == "ASLS":
                            steps.append(rp.preprocessing.baseline.ASLS())
                        else:
                            steps.append(rp.preprocessing.baseline.Poly(poly_order=poly_order))

                    if use_normalize:
                        if normalize_method == "MinMax":
                            steps.append(rp.preprocessing.normalise.MinMax())
                        elif normalize_method == "AUC":
                            steps.append(rp.preprocessing.normalise.AUC())
                        elif normalize_method == "Vector":
                            steps.append(rp.preprocessing.normalise.Vector())
                        else:
                            steps.append(rp.preprocessing.normalise.SNV())

                    # T·∫°o v√† √°p d·ª•ng pipeline
                    pipeline = rp.preprocessing.Pipeline(steps)
                    st.session_state.preprocessed_data = pipeline.apply(st.session_state.data)
                    st.session_state.pipeline_steps = steps

                    st.success(f"‚úÖ ƒê√£ √°p d·ª•ng {len(steps)} b∆∞·ªõc ti·ªÅn x·ª≠ l√Ω!")

            except Exception as e:
                st.error(f"‚ùå L·ªói khi x·ª≠ l√Ω: {str(e)}")

    with col_btn2:
        if st.button("üîÑ Reset Pipeline", use_container_width=True):
            st.session_state.preprocessed_data = None
            st.session_state.pipeline_steps = []
            st.info("ƒê√£ reset pipeline")

    with col_btn3:
        # Batch preprocessing for collection
        selected_in_collection = [s for s in st.session_state.spectra_collection if s['selected']]
        if len(selected_in_collection) > 0:
            if st.button(f"‚öôÔ∏è √Åp d·ª•ng cho Collection ({len(selected_in_collection)})", use_container_width=True):
                try:
                    with st.spinner(f"ƒêang x·ª≠ l√Ω {len(selected_in_collection)} ph·ªï..."):
                        # X√¢y d·ª±ng pipeline
                        steps = []

                        if use_cropping:
                            steps.append(rp.preprocessing.misc.Cropper(region=(crop_min, crop_max)))

                        if use_despike:
                            steps.append(rp.preprocessing.despike.WhitakerHayes(
                                kernel_size=despike_kernel,
                                threshold=despike_threshold
                            ))

                        if use_denoise:
                            if denoise_method == "SavGol":
                                steps.append(rp.preprocessing.denoise.SavGol(window_length=window_length, polyorder=polyorder))
                            elif denoise_method == "Gaussian":
                                steps.append(rp.preprocessing.denoise.Gaussian(sigma=sigma))
                            else:
                                steps.append(rp.preprocessing.denoise.Wavelet())

                        if use_baseline:
                            if baseline_method == "ASPLS":
                                steps.append(rp.preprocessing.baseline.ASPLS())
                            elif baseline_method == "ASLS":
                                steps.append(rp.preprocessing.baseline.ASLS())
                            else:
                                steps.append(rp.preprocessing.baseline.Poly(poly_order=poly_order))

                        if use_normalize:
                            if normalize_method == "MinMax":
                                steps.append(rp.preprocessing.normalise.MinMax())
                            elif normalize_method == "AUC":
                                steps.append(rp.preprocessing.normalise.AUC())
                            elif normalize_method == "Vector":
                                steps.append(rp.preprocessing.normalise.Vector())
                            else:
                                steps.append(rp.preprocessing.normalise.SNV())

                        # T·∫°o pipeline
                        pipeline = rp.preprocessing.Pipeline(steps)

                        # √Åp d·ª•ng cho t·ª´ng ph·ªï ƒë∆∞·ª£c ch·ªçn
                        success_count = 0
                        for item in st.session_state.spectra_collection:
                            if item['selected']:
                                try:
                                    item['preprocessed'] = pipeline.apply(item['data'])
                                    success_count += 1
                                except Exception as e:
                                    st.warning(f"L·ªói khi x·ª≠ l√Ω '{item['name']}': {str(e)}")

                        st.success(f"‚úÖ ƒê√£ x·ª≠ l√Ω {success_count}/{len(selected_in_collection)} ph·ªï v·ªõi {len(steps)} b∆∞·ªõc!")
                        st.info("üí° Gi·ªù b·∫°n c√≥ th·ªÉ k·∫øt h·ª£p c√°c ph·ªï ƒë√£ x·ª≠ l√Ω ƒë·ªÉ ch·∫°y PCA.")

                except Exception as e:
                    st.error(f"‚ùå L·ªói khi x·ª≠ l√Ω: {str(e)}")
        else:
            st.info("üí° Ch·ªçn ph·ªï trong Collection ƒë·ªÉ x·ª≠ l√Ω h√†ng lo·∫°t")

    # So s√°nh tr∆∞·ªõc/sau
    if st.session_state.preprocessed_data is not None:
        st.markdown("---")
        st.write("### üìä So s√°nh tr∆∞·ªõc v√† sau x·ª≠ l√Ω")

        col_before, col_after = st.columns(2)

        try:
            # L·∫•y ph·ªï m·∫´u
            data_type = type(st.session_state.data).__name__

            if data_type == 'Spectrum':
                # Spectrum ƒë∆°n l·∫ª
                raw_spectrum = st.session_state.data
                processed_spectrum = st.session_state.preprocessed_data
            elif hasattr(st.session_state.data, 'flat'):
                # Volumetric data
                raw_spectrum = st.session_state.data.flat[0]
                processed_spectrum = st.session_state.preprocessed_data.flat[0]
            elif hasattr(st.session_state.data, '__len__') and len(st.session_state.data.shape) > 1:
                # Multi-spectrum data
                raw_spectrum = st.session_state.data[0]
                processed_spectrum = st.session_state.preprocessed_data[0]
            else:
                raw_spectrum = st.session_state.data
                processed_spectrum = st.session_state.preprocessed_data

            with col_before:
                st.write("**Tr∆∞·ªõc x·ª≠ l√Ω**")
                fig1, ax1 = plt.subplots(figsize=(6, 4))

                # Plot tr·ª±c ti·∫øp v·ªõi matplotlib ƒë·ªÉ tr√°nh l·ªói indexing
                if hasattr(raw_spectrum, 'spectral_axis') and hasattr(raw_spectrum, 'spectral_data'):
                    ax1.plot(raw_spectrum.spectral_axis, raw_spectrum.spectral_data, linewidth=1.5)
                    ax1.set_xlabel("Wavenumber (cm‚Åª¬π)")
                    ax1.set_ylabel("Intensity")
                else:
                    rp.plot.spectra(raw_spectrum, ax=ax1)

                ax1.set_title("Ph·ªï g·ªëc")
                ax1.grid(True, alpha=0.3)
                st.pyplot(fig1)
                plt.close()

            with col_after:
                st.write("**Sau x·ª≠ l√Ω**")
                fig2, ax2 = plt.subplots(figsize=(6, 4))

                # Plot tr·ª±c ti·∫øp v·ªõi matplotlib ƒë·ªÉ tr√°nh l·ªói indexing
                if hasattr(processed_spectrum, 'spectral_axis') and hasattr(processed_spectrum, 'spectral_data'):
                    ax2.plot(processed_spectrum.spectral_axis, processed_spectrum.spectral_data, linewidth=1.5)
                    ax2.set_xlabel("Wavenumber (cm‚Åª¬π)")
                    ax2.set_ylabel("Intensity")
                else:
                    rp.plot.spectra(processed_spectrum, ax=ax2)

                ax2.set_title("Ph·ªï ƒë√£ x·ª≠ l√Ω")
                ax2.grid(True, alpha=0.3)
                st.pyplot(fig2)
                plt.close()

        except Exception as e:
            st.error(f"L·ªói khi hi·ªÉn th·ªã so s√°nh: {str(e)}")

# ==================== TRANG PH√ÇN T√çCH ====================
elif page == "Ph√¢n t√≠ch":
    st.markdown('<p class="sub-header">üî¨ Ph√¢n t√≠ch ph·ªï</p>', unsafe_allow_html=True)

    # Ki·ªÉm tra d·ªØ li·ªáu
    if st.session_state.data is None:
        st.warning("‚ö†Ô∏è Vui l√≤ng t·∫£i d·ªØ li·ªáu tr∆∞·ªõc!")
        st.stop()

    # S·ª≠ d·ª•ng d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω n·∫øu c√≥, kh√¥ng th√¨ d√πng d·ªØ li·ªáu g·ªëc
    data_to_analyze = st.session_state.preprocessed_data if st.session_state.preprocessed_data is not None else st.session_state.data

    if st.session_state.preprocessed_data is None:
        st.info("üí° ƒêang s·ª≠ d·ª•ng d·ªØ li·ªáu g·ªëc. Khuy·∫øn ngh·ªã ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu tr∆∞·ªõc khi ph√¢n t√≠ch.")

    # Debug info
    st.write(f"**Lo·∫°i d·ªØ li·ªáu ph√¢n t√≠ch:** {type(data_to_analyze).__name__}")

    st.write("### Ch·ªçn ph∆∞∆°ng ph√°p ph√¢n t√≠ch")

    analysis_method = st.selectbox(
        "Ph∆∞∆°ng ph√°p:",
        ["Spectral Unmixing (N-FINDR)", "Peak Detection", "Component Analysis (PCA)"]
    )

    # Spectral Unmixing
    if analysis_method == "Spectral Unmixing (N-FINDR)":
        st.write("#### Spectral Unmixing - N-FINDR")
        st.write("Ph√¢n t√°ch ph·ªï th√†nh c√°c th√†nh ph·∫ßn endmember v√† b·∫£n ƒë·ªì phong ph√∫")

        col1, col2 = st.columns([2, 1])

        with col1:
            n_endmembers = st.slider("S·ªë endmembers:", 2, 10, 5)

        with col2:
            st.info("üí° S·ªë endmembers l√† s·ªë th√†nh ph·∫ßn c∆° b·∫£n trong m·∫´u")

        if st.button("‚ñ∂Ô∏è Ch·∫°y Unmixing", type="primary"):
            try:
                # Ki·ªÉm tra n·∫øu l√† Spectrum ƒë∆°n l·∫ª
                data_type = type(data_to_analyze).__name__

                # Ki·ªÉm tra shape ƒë·ªÉ x√°c ƒë·ªãnh c√≥ ph·∫£i single spectrum kh√¥ng
                if data_type == 'Spectrum':
                    if hasattr(data_to_analyze, 'spectral_data'):
                        data_shape = data_to_analyze.spectral_data.shape
                    else:
                        data_shape = data_to_analyze.shape if hasattr(data_to_analyze, 'shape') else (1,)

                    # N·∫øu l√† 1D ho·∫∑c shape[0] == 1, l√† single spectrum
                    if len(data_shape) == 1 or (len(data_shape) > 1 and data_shape[0] == 1):
                        st.error("‚ùå Spectral Unmixing c·∫ßn nhi·ªÅu ph·ªï (·∫£nh ho·∫∑c volumetric data).")
                        st.info("üí° V·ªõi 1 ph·ªï ƒë∆°n l·∫ª, s·ª≠ d·ª•ng Peak Detection thay v√¨ Unmixing.")
                        st.stop()

                with st.spinner("ƒêang ph√¢n t√≠ch..."):
                    unmixer = rp.analysis.unmix.NFINDR(n_endmembers=n_endmembers)
                    abundance_maps, endmembers = unmixer.apply(data_to_analyze)

                    st.session_state.analysis_results = {
                        'type': 'unmixing',
                        'abundance_maps': abundance_maps,
                        'endmembers': endmembers,
                        'data': data_to_analyze
                    }

                    st.success(f"‚úÖ ƒê√£ ph√¢n t√°ch th√†nh {n_endmembers} endmembers!")

            except Exception as e:
                st.error(f"‚ùå L·ªói khi ph√¢n t√≠ch: {str(e)}")

    # Peak Detection
    elif analysis_method == "Peak Detection":
        st.write("#### Peak Detection")
        st.write("T√¨m c√°c peak trong ph·ªï")

        col1, col2 = st.columns(2)

        with col1:
            prominence = st.slider("Prominence:", 0.01, 1.0, 0.1, 0.01)

        with col2:
            distance = st.slider("Distance (s·ªë ƒëi·ªÉm):", 5, 100, 20)

        if st.button("‚ñ∂Ô∏è T√¨m Peaks", type="primary"):
            try:
                from scipy.signal import find_peaks

                with st.spinner("ƒêang t√¨m peaks..."):
                    # L·∫•y ph·ªï ƒë·ªÉ ph√¢n t√≠ch
                    data_type = type(data_to_analyze).__name__

                    if data_type == 'Spectrum':
                        # Spectrum ƒë∆°n l·∫ª
                        spectrum = data_to_analyze
                    elif hasattr(data_to_analyze, 'flat'):
                        # Volumetric data
                        spectrum = data_to_analyze.flat[0]
                    elif hasattr(data_to_analyze, '__len__') and len(data_to_analyze.shape) > 1:
                        # Multi-spectrum data
                        spectrum = data_to_analyze[0]
                    else:
                        spectrum = data_to_analyze

                    # L·∫•y intensities m·ªôt c√°ch an to√†n
                    if hasattr(spectrum, 'spectral_data'):
                        intensities = spectrum.spectral_data
                    elif hasattr(spectrum, 'flat'):
                        intensities = spectrum.flat
                    elif isinstance(spectrum, np.ndarray):
                        intensities = spectrum
                    else:
                        # Fallback: chuy·ªÉn v·ªÅ numpy array
                        intensities = np.array(spectrum)

                    # ƒê·∫£m b·∫£o l√† 1D array
                    if len(intensities.shape) > 1:
                        intensities = intensities.flatten()

                    # T√¨m peaks
                    peaks, properties = find_peaks(intensities, prominence=prominence, distance=distance)

                    # L·∫•y spectral axis an to√†n
                    if hasattr(spectrum, 'spectral_axis'):
                        spectral_axis = spectrum.spectral_axis
                    else:
                        # N·∫øu kh√¥ng c√≥, t·∫°o index array
                        spectral_axis = np.arange(len(intensities))

                    st.session_state.analysis_results = {
                        'type': 'peaks',
                        'spectrum': spectrum,
                        'peaks': peaks,
                        'properties': properties,
                        'intensities': intensities,
                        'spectral_axis': spectral_axis
                    }

                    st.success(f"‚úÖ ƒê√£ t√¨m th·∫•y {len(peaks)} peaks!")

            except Exception as e:
                st.error(f"‚ùå L·ªói khi t√¨m peaks: {str(e)}")

    # PCA
    elif analysis_method == "Component Analysis (PCA)":
        st.write("#### Principal Component Analysis (PCA)")
        st.write("Ph√¢n t√≠ch th√†nh ph·∫ßn ch√≠nh")

        n_components = st.slider("S·ªë components:", 2, 10, 3)

        if st.button("‚ñ∂Ô∏è Ch·∫°y PCA", type="primary"):
            try:
                from sklearn.decomposition import PCA

                with st.spinner("ƒêang ph√¢n t√≠ch PCA..."):
                    # Chu·∫©n b·ªã d·ªØ li·ªáu
                    data_type = type(data_to_analyze).__name__

                    if data_type == 'Spectrum':
                        # Spectrum ƒë∆°n l·∫ª - PCA c·∫ßn √≠t nh·∫•t 2 m·∫´u
                        st.error("‚ùå PCA c·∫ßn √≠t nh·∫•t 2 ph·ªï. D·ªØ li·ªáu hi·ªán t·∫°i ch·ªâ c√≥ 1 ph·ªï ƒë∆°n l·∫ª.")
                        st.info("üí° S·ª≠ d·ª•ng d·ªØ li·ªáu t·ªïng h·ª£p ho·∫∑c t·∫£i nhi·ªÅu ph·ªï ƒë·ªÉ ch·∫°y PCA.")
                        st.stop()
                    elif hasattr(data_to_analyze, 'flat'):
                        # Volumetric data
                        data_matrix = data_to_analyze.flat.spectral_data
                    else:
                        data_matrix = data_to_analyze.spectral_data if hasattr(data_to_analyze, 'spectral_data') else data_to_analyze

                    # Reshape n·∫øu c·∫ßn
                    if len(data_matrix.shape) > 2:
                        original_shape = data_matrix.shape
                        data_matrix = data_matrix.reshape(-1, data_matrix.shape[-1])
                    elif len(data_matrix.shape) == 1:
                        # N·∫øu ch·ªâ c√≥ 1 ph·ªï, kh√¥ng th·ªÉ ch·∫°y PCA
                        st.error("‚ùå PCA c·∫ßn √≠t nh·∫•t 2 ph·ªï ƒë·ªÉ ph√¢n t√≠ch.")
                        st.stop()

                    # Ch·∫°y PCA
                    pca = PCA(n_components=n_components)
                    scores = pca.fit_transform(data_matrix)
                    loadings = pca.components_

                    st.session_state.analysis_results = {
                        'type': 'pca',
                        'scores': scores,
                        'loadings': loadings,
                        'explained_variance': pca.explained_variance_ratio_,
                        'data': data_to_analyze
                    }

                    st.success(f"‚úÖ ƒê√£ ho√†n th√†nh PCA v·ªõi {n_components} components!")

            except Exception as e:
                st.error(f"‚ùå L·ªói khi ch·∫°y PCA: {str(e)}")

# ==================== TRANG TR·ª∞C QUAN H√ìA ====================
elif page == "Tr·ª±c quan h√≥a":
    st.markdown('<p class="sub-header">üìä Tr·ª±c quan h√≥a k·∫øt qu·∫£</p>', unsafe_allow_html=True)

    if st.session_state.analysis_results is None:
        st.warning("‚ö†Ô∏è Vui l√≤ng ch·∫°y ph√¢n t√≠ch tr∆∞·ªõc!")
        st.stop()

    results = st.session_state.analysis_results
    result_type = results['type']

    # Hi·ªÉn th·ªã theo lo·∫°i ph√¢n t√≠ch
    if result_type == 'unmixing':
        st.write("### K·∫øt qu·∫£ Spectral Unmixing")

        endmembers = results['endmembers']
        abundance_maps = results['abundance_maps']
        data = results['data']

        # Plot endmembers
        st.write("#### üî¨ Endmembers")
        fig1, ax1 = plt.subplots(figsize=(12, 6))

        if hasattr(data, 'spectral_axis'):
            rp.plot.spectra(endmembers, wavenumber_axis=data.spectral_axis, ax=ax1, plot_type='single stacked')
        else:
            rp.plot.spectra(endmembers, ax=ax1, plot_type='single stacked')

        ax1.set_title("Endmember Spectra")
        st.pyplot(fig1)
        plt.close()

        # Plot abundance maps
        st.write("#### üó∫Ô∏è Abundance Maps")

        try:
            # N·∫øu l√† volumetric data, l·∫•y m·ªôt layer
            if len(abundance_maps[0].shape) == 3:
                layer_idx = st.slider("Ch·ªçn layer:", 0, abundance_maps[0].shape[2]-1, abundance_maps[0].shape[2]//2)

                fig2, axes = plt.subplots(1, len(abundance_maps), figsize=(4*len(abundance_maps), 4))
                if len(abundance_maps) == 1:
                    axes = [axes]

                for i, (amap, ax) in enumerate(zip(abundance_maps, axes)):
                    im = ax.imshow(amap[:, :, layer_idx], cmap='viridis')
                    ax.set_title(f"Endmember {i+1}")
                    plt.colorbar(im, ax=ax)

                st.pyplot(fig2)
                plt.close()

            else:
                # 2D data
                fig2, axes = plt.subplots(1, len(abundance_maps), figsize=(4*len(abundance_maps), 4))
                if len(abundance_maps) == 1:
                    axes = [axes]

                for i, (amap, ax) in enumerate(zip(abundance_maps, axes)):
                    im = ax.imshow(amap, cmap='viridis')
                    ax.set_title(f"Endmember {i+1}")
                    plt.colorbar(im, ax=ax)

                st.pyplot(fig2)
                plt.close()

        except Exception as e:
            st.warning(f"Kh√¥ng th·ªÉ hi·ªÉn th·ªã abundance maps: {str(e)}")

    elif result_type == 'peaks':
        st.write("### K·∫øt qu·∫£ Peak Detection")

        peaks = results['peaks']
        intensities = results['intensities']
        spectral_axis = results['spectral_axis']

        fig, ax = plt.subplots(figsize=(12, 6))

        # Plot spectrum
        ax.plot(spectral_axis, intensities, 'b-', linewidth=1.5, label='Spectrum')
        ax.plot(spectral_axis[peaks], intensities[peaks], 'ro', markersize=8, label='Peaks')

        # ƒê√°nh d·∫•u peaks
        for peak in peaks:
            ax.axvline(spectral_axis[peak], color='r', linestyle='--', alpha=0.3)
            ax.text(spectral_axis[peak], intensities[peak], f'{spectral_axis[peak]:.0f}',
                   rotation=45, ha='right', va='bottom', fontsize=8)

        ax.set_xlabel('Wavenumber (cm‚Åª¬π)')
        ax.set_ylabel('Intensity')
        ax.set_title(f'Peak Detection - {len(peaks)} peaks found')
        ax.legend()
        ax.grid(True, alpha=0.3)

        st.pyplot(fig)
        plt.close()

        # B·∫£ng th√¥ng tin peaks
        st.write("#### üìã Danh s√°ch Peaks")
        peak_data = {
            'Peak #': range(1, len(peaks)+1),
            'Position (index)': peaks,
            'Wavenumber (cm‚Åª¬π)': [f"{spectral_axis[p]:.2f}" for p in peaks],
            'Intensity': [f"{intensities[p]:.4f}" for p in peaks]
        }

        import pandas as pd
        df = pd.DataFrame(peak_data)
        st.dataframe(df, use_container_width=True)

    elif result_type == 'pca':
        st.write("### K·∫øt qu·∫£ PCA")

        scores = results['scores']
        loadings = results['loadings']
        explained_variance = results['explained_variance']

        col1, col2 = st.columns(2)

        with col1:
            # Scree plot
            st.write("#### üìä Explained Variance")
            fig1, ax1 = plt.subplots(figsize=(6, 4))
            ax1.bar(range(1, len(explained_variance)+1), explained_variance * 100)
            ax1.set_xlabel('Principal Component')
            ax1.set_ylabel('Explained Variance (%)')
            ax1.set_title('Scree Plot')
            st.pyplot(fig1)
            plt.close()

        with col2:
            # Score plot
            st.write("#### üéØ Score Plot (PC1 vs PC2)")
            fig2, ax2 = plt.subplots(figsize=(6, 4))
            ax2.scatter(scores[:, 0], scores[:, 1], alpha=0.6)
            ax2.set_xlabel(f'PC1 ({explained_variance[0]*100:.1f}%)')
            ax2.set_ylabel(f'PC2 ({explained_variance[1]*100:.1f}%)')
            ax2.set_title('PCA Score Plot')
            ax2.grid(True, alpha=0.3)
            st.pyplot(fig2)
            plt.close()

        # Loading plot
        st.write("#### üìà Loading Plots")
        fig3, axes = plt.subplots(1, min(3, len(loadings)), figsize=(12, 4))
        if len(loadings) == 1:
            axes = [axes]

        for i, ax in enumerate(axes[:len(loadings)]):
            ax.plot(loadings[i])
            ax.set_title(f'PC{i+1} Loading')
            ax.set_xlabel('Wavenumber index')
            ax.set_ylabel('Loading')
            ax.grid(True, alpha=0.3)

        plt.tight_layout()
        st.pyplot(fig3)
        plt.close()

# Footer
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: gray;'>
    <p>RamanSPy GUI v1.0 | ƒê∆∞·ª£c x√¢y d·ª±ng v·ªõi Streamlit</p>
    <p>T√†i li·ªáu: <a href='https://ramanspy.readthedocs.io'>ramanspy.readthedocs.io</a></p>
</div>
""", unsafe_allow_html=True)
