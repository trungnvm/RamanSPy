"""
RamanSPy GUI - Giao di·ªán ƒë·ªì h·ªça cho ph√¢n t√≠ch ph·ªï Raman
Ch·∫°y ·ª©ng d·ª•ng: streamlit run ramanspy_gui.py
"""

import streamlit as st
import ramanspy as rp
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import tempfile
import os

# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="RamanSPy GUI",
    page_icon="üî¨",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS t√πy ch·ªânh
st.markdown("""
    <style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.5rem;
        font-weight: bold;
        color: #2ca02c;
        margin-top: 2rem;
        margin-bottom: 1rem;
    }
    </style>
""", unsafe_allow_html=True)

# Header
st.markdown('<p class="main-header">üî¨ RamanSPy - Ph√¢n t√≠ch ph·ªï Raman</p>', unsafe_allow_html=True)

# Kh·ªüi t·∫°o session state
if 'data' not in st.session_state:
    st.session_state.data = None
if 'preprocessed_data' not in st.session_state:
    st.session_state.preprocessed_data = None
if 'pipeline_steps' not in st.session_state:
    st.session_state.pipeline_steps = []
if 'analysis_results' not in st.session_state:
    st.session_state.analysis_results = None

# Sidebar - Navigation
st.sidebar.title("üìã Menu")
page = st.sidebar.radio(
    "Ch·ªçn ch·ª©c nƒÉng:",
    ["T·∫£i d·ªØ li·ªáu", "Ti·ªÅn x·ª≠ l√Ω", "Ph√¢n t√≠ch", "Tr·ª±c quan h√≥a"]
)

st.sidebar.markdown("---")
st.sidebar.info("""
**RamanSPy GUI v1.0**

C√¥ng c·ª• ph√¢n t√≠ch ph·ªï Raman ƒë∆°n gi·∫£n v√† d·ªÖ s·ª≠ d·ª•ng.

[T√†i li·ªáu](https://ramanspy.readthedocs.io)
""")

# ==================== TRANG T·∫¢I D·ªÆ LI·ªÜU ====================
if page == "T·∫£i d·ªØ li·ªáu":
    st.markdown('<p class="sub-header">üìÇ T·∫£i d·ªØ li·ªáu ph·ªï Raman</p>', unsafe_allow_html=True)

    tab1, tab2, tab3 = st.tabs(["üìÅ T·∫£i t·ª´ file", "üìä D·ªØ li·ªáu m·∫´u", "üé≤ D·ªØ li·ªáu t·ªïng h·ª£p"])

    # Tab 1: T·∫£i t·ª´ file
    with tab1:
        st.write("### T·∫£i d·ªØ li·ªáu t·ª´ file")

        col1, col2 = st.columns([2, 1])

        with col1:
            file_format = st.selectbox(
                "Ch·ªçn ƒë·ªãnh d·∫°ng file:",
                ["CSV/Text (t√πy ch·ªânh)", "WITec", "Renishaw", "NumPy (.npy)"]
            )

        with col2:
            st.info("üí° Ch·ªçn ƒë√∫ng ƒë·ªãnh d·∫°ng c·ªßa thi·∫øt b·ªã ƒëo")

        # H∆∞·ªõng d·∫´n cho CSV/Text
        if file_format == "CSV/Text (t√πy ch·ªânh)":
            with st.expander("‚ÑπÔ∏è ƒê·ªãnh d·∫°ng CSV/Text ƒë∆∞·ª£c h·ªó tr·ª£"):
                st.write("""
                **ƒê·ªãnh d·∫°ng file ƒë∆∞·ª£c h·ªó tr·ª£:**
                - Header (t√πy ch·ªçn) v·ªõi metadata
                - D·ªØ li·ªáu 2 c·ªôt: Wavenumber v√† Intensity
                - Ph√¢n c√°ch b·∫±ng: `;` , `,` , tab ho·∫∑c kho·∫£ng tr·∫Øng

                **V√≠ d·ª•:**
                ```
                Name=Andor Spectra
                X=Raman Shift, 1/cm
                Y=Intensity, Counts
                2.37; 2405
                6.04; 2446
                9.70; 2369
                ...
                ```
                """)

        uploaded_file = st.file_uploader(
            "Ch·ªçn file d·ªØ li·ªáu:",
            type=['txt', 'csv', 'wdf', 'npy', 'npz', 'dat'],
            help="H·ªó tr·ª£ nhi·ªÅu ƒë·ªãnh d·∫°ng file t·ª´ c√°c thi·∫øt b·ªã Raman kh√°c nhau"
        )

        if uploaded_file is not None:
            try:
                # L∆∞u file t·∫°m
                with tempfile.NamedTemporaryFile(delete=False, suffix=Path(uploaded_file.name).suffix) as tmp_file:
                    tmp_file.write(uploaded_file.getvalue())
                    tmp_path = tmp_file.name

                with st.spinner("ƒêang t·∫£i d·ªØ li·ªáu..."):
                    # Load d·ªØ li·ªáu theo ƒë·ªãnh d·∫°ng
                    if file_format == "WITec":
                        st.session_state.data = rp.load.witec(tmp_path)
                    elif file_format == "Renishaw":
                        st.session_state.data = rp.load.renishaw(tmp_path)
                    elif file_format == "NumPy (.npy)":
                        data_array = np.load(tmp_path)
                        st.session_state.data = rp.Spectrum(data_array)
                    else:
                        # CSV/Text (t√πy ch·ªânh)
                        # ƒê·ªçc file v√† x·ª≠ l√Ω
                        with open(tmp_path, 'r', encoding='utf-8') as f:
                            lines = f.readlines()

                        # T√¨m d√≤ng b·∫Øt ƒë·∫ßu d·ªØ li·ªáu (b·ªè qua header)
                        data_start = 0
                        for i, line in enumerate(lines):
                            # Ki·ªÉm tra n·∫øu d√≤ng ch·ª©a s·ªë (d·ªØ li·ªáu)
                            if line.strip() and (line.strip()[0].isdigit() or line.strip()[0] == '-'):
                                data_start = i
                                break

                        # Parse d·ªØ li·ªáu
                        wavenumbers = []
                        intensities = []

                        for line in lines[data_start:]:
                            line = line.strip()
                            if not line:
                                continue

                            # Th·ª≠ c√°c delimiter kh√°c nhau
                            if ';' in line:
                                parts = line.split(';')
                            elif ',' in line:
                                parts = line.split(',')
                            elif '\t' in line:
                                parts = line.split('\t')
                            else:
                                parts = line.split()

                            if len(parts) >= 2:
                                try:
                                    wavenumbers.append(float(parts[0].strip()))
                                    intensities.append(float(parts[1].strip()))
                                except ValueError:
                                    continue

                        # T·∫°o Spectrum object
                        if len(wavenumbers) > 0 and len(intensities) > 0:
                            st.session_state.data = rp.Spectrum(
                                np.array(intensities),
                                spectral_axis=np.array(wavenumbers)
                            )
                        else:
                            raise ValueError("Kh√¥ng th·ªÉ ƒë·ªçc d·ªØ li·ªáu t·ª´ file. Vui l√≤ng ki·ªÉm tra ƒë·ªãnh d·∫°ng.")

                os.unlink(tmp_path)
                st.success(f"‚úÖ ƒê√£ t·∫£i th√†nh c√¥ng: {uploaded_file.name}")

                # Hi·ªÉn th·ªã th√¥ng tin d·ªØ li·ªáu
                st.write("### Th√¥ng tin d·ªØ li·ªáu")
                col1, col2, col3 = st.columns(3)

                with col1:
                    st.metric("Ki·ªÉu d·ªØ li·ªáu", type(st.session_state.data).__name__)
                with col2:
                    st.metric("K√≠ch th∆∞·ªõc", str(st.session_state.data.shape))
                with col3:
                    if hasattr(st.session_state.data, 'spectral_axis'):
                        st.metric("S·ªë ƒëi·ªÉm ph·ªï", len(st.session_state.data.spectral_axis))

            except Exception as e:
                st.error(f"‚ùå L·ªói khi t·∫£i file: {str(e)}")

    # Tab 2: D·ªØ li·ªáu m·∫´u
    with tab2:
        st.write("### T·∫£i d·ªØ li·ªáu m·∫´u t·ª´ RamanSPy")

        st.info("üì• D·ªØ li·ªáu s·∫Ω ƒë∆∞·ª£c t·∫£i xu·ªëng t·ª± ƒë·ªông t·ª´ repository")

        dataset_type = st.selectbox(
            "Ch·ªçn lo·∫°i d·ªØ li·ªáu:",
            ["THP-1 cells", "MCF-7 cells", "Bacteria dataset"]
        )

        col1, col2 = st.columns([1, 3])

        with col1:
            if st.button("üì• T·∫£i d·ªØ li·ªáu m·∫´u", type="primary"):
                try:
                    with st.spinner("ƒêang t·∫£i d·ªØ li·ªáu m·∫´u..."):
                        data_dir = "./data/kallepitis_data"

                        # Ch·ªçn cell type
                        if dataset_type == "THP-1 cells":
                            cell_type = 'THP-1'
                        elif dataset_type == "MCF-7 cells":
                            cell_type = 'MCF-7'
                        else:
                            cell_type = 'THP-1'

                        volumes = rp.datasets.volumetric_cells(cell_type=cell_type, folder=data_dir)
                        st.session_state.data = volumes[0]

                        st.success(f"‚úÖ ƒê√£ t·∫£i d·ªØ li·ªáu m·∫´u: {dataset_type}")
                        st.rerun()

                except Exception as e:
                    st.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ t·∫£i d·ªØ li·ªáu m·∫´u: {str(e)}")
                    st.info("D·ªØ li·ªáu m·∫´u c·∫ßn ƒë∆∞·ª£c t·∫£i v·ªÅ tr∆∞·ªõc. B·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng d·ªØ li·ªáu t·ªïng h·ª£p ƒë·ªÉ th·ª≠ nghi·ªám.")

        with col2:
            if dataset_type == "THP-1 cells":
                st.write("**THP-1 cells**: D·ªØ li·ªáu ph·ªï Raman 3D c·ªßa t·∫ø b√†o THP-1")
            elif dataset_type == "MCF-7 cells":
                st.write("**MCF-7 cells**: D·ªØ li·ªáu ph·ªï Raman 3D c·ªßa t·∫ø b√†o MCF-7")

    # Tab 3: D·ªØ li·ªáu t·ªïng h·ª£p
    with tab3:
        st.write("### T·∫°o d·ªØ li·ªáu t·ªïng h·ª£p ƒë·ªÉ th·ª≠ nghi·ªám")

        col1, col2 = st.columns(2)

        with col1:
            n_spectra = st.slider("S·ªë ph·ªï:", 10, 1000, 100)
            n_points = st.slider("S·ªë ƒëi·ªÉm ph·ªï:", 100, 2000, 500)

        with col2:
            noise_level = st.slider("M·ª©c nhi·ªÖu:", 0.0, 0.5, 0.1, 0.05)
            n_peaks = st.slider("S·ªë peak:", 1, 10, 3)

        if st.button("üé≤ T·∫°o d·ªØ li·ªáu t·ªïng h·ª£p", type="primary"):
            with st.spinner("ƒêang t·∫°o d·ªØ li·ªáu..."):
                # T·∫°o tr·ª•c wavenumber
                wavenumbers = np.linspace(400, 2000, n_points)

                # T·∫°o ph·ªï v·ªõi nhi·ªÅu peaks
                spectra_list = []
                for _ in range(n_spectra):
                    spectrum = np.zeros(n_points)

                    # Th√™m peaks ng·∫´u nhi√™n
                    for _ in range(n_peaks):
                        center = np.random.uniform(600, 1800)
                        width = np.random.uniform(20, 80)
                        height = np.random.uniform(0.5, 1.0)

                        # Gaussian peak
                        spectrum += height * np.exp(-((wavenumbers - center) ** 2) / (2 * width ** 2))

                    # Th√™m baseline
                    baseline = np.random.uniform(0.1, 0.3) * np.ones(n_points)
                    spectrum += baseline

                    # Th√™m nhi·ªÖu
                    noise = np.random.normal(0, noise_level, n_points)
                    spectrum += noise

                    spectra_list.append(spectrum)

                # T·∫°o SpectralContainer
                data_array = np.array(spectra_list)
                st.session_state.data = rp.SpectralContainer(data_array, spectral_axis=wavenumbers)

                st.success(f"‚úÖ ƒê√£ t·∫°o {n_spectra} ph·ªï t·ªïng h·ª£p v·ªõi {n_points} ƒëi·ªÉm")

    # Preview d·ªØ li·ªáu n·∫øu ƒë√£ load
    if st.session_state.data is not None:
        st.markdown("---")
        st.write("### üëÄ Preview d·ªØ li·ªáu")

        try:
            # L·∫•y m·ªôt v√†i ph·ªï ƒë·ªÉ hi·ªÉn th·ªã
            data_type = type(st.session_state.data).__name__

            if data_type == 'Spectrum':
                # Spectrum ƒë∆°n l·∫ª
                sample_spectra = st.session_state.data
            elif hasattr(st.session_state.data, 'flat'):
                # Volumetric data
                sample_spectra = st.session_state.data.flat[0:5]
            elif hasattr(st.session_state.data, '__len__') and len(st.session_state.data.shape) > 1:
                sample_spectra = st.session_state.data[0:5]
            else:
                sample_spectra = st.session_state.data

            # Plot
            fig, ax = plt.subplots(figsize=(10, 4))
            rp.plot.spectra(sample_spectra, ax=ax, plot_type='single')
            ax.set_title("Preview ph·ªï Raman")
            ax.set_xlabel("Wavenumber (cm‚Åª¬π)")
            ax.set_ylabel("Intensity")
            ax.grid(True, alpha=0.3)
            st.pyplot(fig)
            plt.close()

        except Exception as e:
            st.error(f"Kh√¥ng th·ªÉ hi·ªÉn th·ªã preview: {str(e)}")

# ==================== TRANG TI·ªÄN X·ª¨ L√ù ====================
elif page == "Ti·ªÅn x·ª≠ l√Ω":
    st.markdown('<p class="sub-header">‚öôÔ∏è Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu</p>', unsafe_allow_html=True)

    if st.session_state.data is None:
        st.warning("‚ö†Ô∏è Vui l√≤ng t·∫£i d·ªØ li·ªáu tr∆∞·ªõc!")
        st.stop()

    st.write("### X√¢y d·ª±ng Pipeline ti·ªÅn x·ª≠ l√Ω")

    # Sidebar cho vi·ªác ch·ªçn c√°c b∆∞·ªõc preprocessing
    st.write("#### Ch·ªçn c√°c b∆∞·ªõc ti·ªÅn x·ª≠ l√Ω:")

    col1, col2 = st.columns([1, 1])

    with col1:
        st.write("**B∆∞·ªõc 1: C·∫Øt v√πng ph·ªï (Cropping)**")
        use_cropping = st.checkbox("S·ª≠ d·ª•ng Cropping", value=True)
        if use_cropping:
            crop_min = st.number_input("Wavenumber min (cm‚Åª¬π):", 400, 2000, 700, 50)
            crop_max = st.number_input("Wavenumber max (cm‚Åª¬π):", 400, 2000, 1800, 50)

    with col2:
        st.write("**B∆∞·ªõc 2: Lo·∫°i b·ªè Cosmic Ray**")
        use_despike = st.checkbox("S·ª≠ d·ª•ng Despike", value=True)
        if use_despike:
            st.info("üí° S·ª≠ d·ª•ng ph∆∞∆°ng ph√°p WhitakerHayes")

    col3, col4 = st.columns([1, 1])

    with col3:
        st.write("**B∆∞·ªõc 3: Kh·ª≠ nhi·ªÖu (Denoising)**")
        use_denoise = st.checkbox("S·ª≠ d·ª•ng Denoising", value=True)
        if use_denoise:
            denoise_method = st.selectbox(
                "Ph∆∞∆°ng ph√°p kh·ª≠ nhi·ªÖu:",
                ["SavGol", "Gaussian", "Wavelet"]
            )

            if denoise_method == "SavGol":
                window_length = st.slider("Window length:", 3, 21, 9, 2)
                polyorder = st.slider("Polynomial order:", 1, 5, 3)
            elif denoise_method == "Gaussian":
                sigma = st.slider("Sigma:", 0.5, 5.0, 1.0, 0.5)

    with col4:
        st.write("**B∆∞·ªõc 4: Hi·ªáu ch·ªânh Baseline**")
        use_baseline = st.checkbox("S·ª≠ d·ª•ng Baseline Correction", value=True)
        if use_baseline:
            baseline_method = st.selectbox(
                "Ph∆∞∆°ng ph√°p baseline:",
                ["ASPLS", "ASLS", "Poly"]
            )

            if baseline_method == "Poly":
                poly_order = st.slider("Polynomial order:", 1, 5, 3)

    col5, col6 = st.columns([1, 1])

    with col5:
        st.write("**B∆∞·ªõc 5: Chu·∫©n h√≥a (Normalization)**")
        use_normalize = st.checkbox("S·ª≠ d·ª•ng Normalization", value=True)
        if use_normalize:
            normalize_method = st.selectbox(
                "Ph∆∞∆°ng ph√°p chu·∫©n h√≥a:",
                ["MinMax", "AUC", "Vector", "SNV"]
            )

    # N√∫t √°p d·ª•ng pipeline
    st.markdown("---")
    col_btn1, col_btn2, col_btn3 = st.columns([1, 1, 1])

    with col_btn1:
        if st.button("‚ñ∂Ô∏è √Åp d·ª•ng Pipeline", type="primary", use_container_width=True):
            try:
                with st.spinner("ƒêang x·ª≠ l√Ω..."):
                    # X√¢y d·ª±ng pipeline
                    steps = []

                    if use_cropping:
                        steps.append(rp.preprocessing.misc.Cropper(region=(crop_min, crop_max)))

                    if use_despike:
                        steps.append(rp.preprocessing.despike.WhitakerHayes())

                    if use_denoise:
                        if denoise_method == "SavGol":
                            steps.append(rp.preprocessing.denoise.SavGol(window_length=window_length, polyorder=polyorder))
                        elif denoise_method == "Gaussian":
                            steps.append(rp.preprocessing.denoise.Gaussian(sigma=sigma))
                        else:
                            steps.append(rp.preprocessing.denoise.Wavelet())

                    if use_baseline:
                        if baseline_method == "ASPLS":
                            steps.append(rp.preprocessing.baseline.ASPLS())
                        elif baseline_method == "ASLS":
                            steps.append(rp.preprocessing.baseline.ASLS())
                        else:
                            steps.append(rp.preprocessing.baseline.Poly(poly_order=poly_order))

                    if use_normalize:
                        if normalize_method == "MinMax":
                            steps.append(rp.preprocessing.normalise.MinMax())
                        elif normalize_method == "AUC":
                            steps.append(rp.preprocessing.normalise.AUC())
                        elif normalize_method == "Vector":
                            steps.append(rp.preprocessing.normalise.Vector())
                        else:
                            steps.append(rp.preprocessing.normalise.SNV())

                    # T·∫°o v√† √°p d·ª•ng pipeline
                    pipeline = rp.preprocessing.Pipeline(steps)
                    st.session_state.preprocessed_data = pipeline.apply(st.session_state.data)
                    st.session_state.pipeline_steps = steps

                    st.success(f"‚úÖ ƒê√£ √°p d·ª•ng {len(steps)} b∆∞·ªõc ti·ªÅn x·ª≠ l√Ω!")

            except Exception as e:
                st.error(f"‚ùå L·ªói khi x·ª≠ l√Ω: {str(e)}")

    with col_btn2:
        if st.button("üîÑ Reset Pipeline", use_container_width=True):
            st.session_state.preprocessed_data = None
            st.session_state.pipeline_steps = []
            st.info("ƒê√£ reset pipeline")

    # So s√°nh tr∆∞·ªõc/sau
    if st.session_state.preprocessed_data is not None:
        st.markdown("---")
        st.write("### üìä So s√°nh tr∆∞·ªõc v√† sau x·ª≠ l√Ω")

        col_before, col_after = st.columns(2)

        try:
            # L·∫•y ph·ªï m·∫´u
            data_type = type(st.session_state.data).__name__

            if data_type == 'Spectrum':
                # Spectrum ƒë∆°n l·∫ª
                raw_spectrum = st.session_state.data
                processed_spectrum = st.session_state.preprocessed_data
            elif hasattr(st.session_state.data, 'flat'):
                # Volumetric data
                raw_spectrum = st.session_state.data.flat[0]
                processed_spectrum = st.session_state.preprocessed_data.flat[0]
            elif hasattr(st.session_state.data, '__len__') and len(st.session_state.data.shape) > 1:
                # Multi-spectrum data
                raw_spectrum = st.session_state.data[0]
                processed_spectrum = st.session_state.preprocessed_data[0]
            else:
                raw_spectrum = st.session_state.data
                processed_spectrum = st.session_state.preprocessed_data

            with col_before:
                st.write("**Tr∆∞·ªõc x·ª≠ l√Ω**")
                fig1, ax1 = plt.subplots(figsize=(6, 4))
                rp.plot.spectra(raw_spectrum, ax=ax1)
                ax1.set_title("Ph·ªï g·ªëc")
                st.pyplot(fig1)
                plt.close()

            with col_after:
                st.write("**Sau x·ª≠ l√Ω**")
                fig2, ax2 = plt.subplots(figsize=(6, 4))
                rp.plot.spectra(processed_spectrum, ax=ax2)
                ax2.set_title("Ph·ªï ƒë√£ x·ª≠ l√Ω")
                st.pyplot(fig2)
                plt.close()

        except Exception as e:
            st.error(f"L·ªói khi hi·ªÉn th·ªã so s√°nh: {str(e)}")

# ==================== TRANG PH√ÇN T√çCH ====================
elif page == "Ph√¢n t√≠ch":
    st.markdown('<p class="sub-header">üî¨ Ph√¢n t√≠ch ph·ªï</p>', unsafe_allow_html=True)

    # Ki·ªÉm tra d·ªØ li·ªáu
    if st.session_state.data is None:
        st.warning("‚ö†Ô∏è Vui l√≤ng t·∫£i d·ªØ li·ªáu tr∆∞·ªõc!")
        st.stop()

    # S·ª≠ d·ª•ng d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω n·∫øu c√≥, kh√¥ng th√¨ d√πng d·ªØ li·ªáu g·ªëc
    data_to_analyze = st.session_state.preprocessed_data if st.session_state.preprocessed_data is not None else st.session_state.data

    if st.session_state.preprocessed_data is None:
        st.info("üí° ƒêang s·ª≠ d·ª•ng d·ªØ li·ªáu g·ªëc. Khuy·∫øn ngh·ªã ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu tr∆∞·ªõc khi ph√¢n t√≠ch.")

    st.write("### Ch·ªçn ph∆∞∆°ng ph√°p ph√¢n t√≠ch")

    analysis_method = st.selectbox(
        "Ph∆∞∆°ng ph√°p:",
        ["Spectral Unmixing (N-FINDR)", "Peak Detection", "Component Analysis (PCA)"]
    )

    # Spectral Unmixing
    if analysis_method == "Spectral Unmixing (N-FINDR)":
        st.write("#### Spectral Unmixing - N-FINDR")
        st.write("Ph√¢n t√°ch ph·ªï th√†nh c√°c th√†nh ph·∫ßn endmember v√† b·∫£n ƒë·ªì phong ph√∫")

        col1, col2 = st.columns([2, 1])

        with col1:
            n_endmembers = st.slider("S·ªë endmembers:", 2, 10, 5)

        with col2:
            st.info("üí° S·ªë endmembers l√† s·ªë th√†nh ph·∫ßn c∆° b·∫£n trong m·∫´u")

        if st.button("‚ñ∂Ô∏è Ch·∫°y Unmixing", type="primary"):
            try:
                with st.spinner("ƒêang ph√¢n t√≠ch..."):
                    unmixer = rp.analysis.unmix.NFINDR(n_endmembers=n_endmembers)
                    abundance_maps, endmembers = unmixer.apply(data_to_analyze)

                    st.session_state.analysis_results = {
                        'type': 'unmixing',
                        'abundance_maps': abundance_maps,
                        'endmembers': endmembers,
                        'data': data_to_analyze
                    }

                    st.success(f"‚úÖ ƒê√£ ph√¢n t√°ch th√†nh {n_endmembers} endmembers!")

            except Exception as e:
                st.error(f"‚ùå L·ªói khi ph√¢n t√≠ch: {str(e)}")

    # Peak Detection
    elif analysis_method == "Peak Detection":
        st.write("#### Peak Detection")
        st.write("T√¨m c√°c peak trong ph·ªï")

        col1, col2 = st.columns(2)

        with col1:
            prominence = st.slider("Prominence:", 0.01, 1.0, 0.1, 0.01)

        with col2:
            distance = st.slider("Distance (s·ªë ƒëi·ªÉm):", 5, 100, 20)

        if st.button("‚ñ∂Ô∏è T√¨m Peaks", type="primary"):
            try:
                from scipy.signal import find_peaks

                with st.spinner("ƒêang t√¨m peaks..."):
                    # L·∫•y ph·ªï ƒë·∫ßu ti√™n ƒë·ªÉ ph√¢n t√≠ch
                    if hasattr(data_to_analyze, 'flat'):
                        spectrum = data_to_analyze.flat[0]
                    elif hasattr(data_to_analyze, '__getitem__'):
                        spectrum = data_to_analyze[0]
                    else:
                        spectrum = data_to_analyze

                    # T√¨m peaks
                    intensities = spectrum.spectral_data if hasattr(spectrum, 'spectral_data') else spectrum
                    peaks, properties = find_peaks(intensities, prominence=prominence, distance=distance)

                    st.session_state.analysis_results = {
                        'type': 'peaks',
                        'spectrum': spectrum,
                        'peaks': peaks,
                        'properties': properties
                    }

                    st.success(f"‚úÖ ƒê√£ t√¨m th·∫•y {len(peaks)} peaks!")

            except Exception as e:
                st.error(f"‚ùå L·ªói khi t√¨m peaks: {str(e)}")

    # PCA
    elif analysis_method == "Component Analysis (PCA)":
        st.write("#### Principal Component Analysis (PCA)")
        st.write("Ph√¢n t√≠ch th√†nh ph·∫ßn ch√≠nh")

        n_components = st.slider("S·ªë components:", 2, 10, 3)

        if st.button("‚ñ∂Ô∏è Ch·∫°y PCA", type="primary"):
            try:
                from sklearn.decomposition import PCA

                with st.spinner("ƒêang ph√¢n t√≠ch PCA..."):
                    # Chu·∫©n b·ªã d·ªØ li·ªáu
                    if hasattr(data_to_analyze, 'flat'):
                        data_matrix = data_to_analyze.flat.spectral_data
                    else:
                        data_matrix = data_to_analyze.spectral_data if hasattr(data_to_analyze, 'spectral_data') else data_to_analyze

                    # Reshape n·∫øu c·∫ßn
                    if len(data_matrix.shape) > 2:
                        original_shape = data_matrix.shape
                        data_matrix = data_matrix.reshape(-1, data_matrix.shape[-1])

                    # Ch·∫°y PCA
                    pca = PCA(n_components=n_components)
                    scores = pca.fit_transform(data_matrix)
                    loadings = pca.components_

                    st.session_state.analysis_results = {
                        'type': 'pca',
                        'scores': scores,
                        'loadings': loadings,
                        'explained_variance': pca.explained_variance_ratio_,
                        'data': data_to_analyze
                    }

                    st.success(f"‚úÖ ƒê√£ ho√†n th√†nh PCA v·ªõi {n_components} components!")

            except Exception as e:
                st.error(f"‚ùå L·ªói khi ch·∫°y PCA: {str(e)}")

# ==================== TRANG TR·ª∞C QUAN H√ìA ====================
elif page == "Tr·ª±c quan h√≥a":
    st.markdown('<p class="sub-header">üìä Tr·ª±c quan h√≥a k·∫øt qu·∫£</p>', unsafe_allow_html=True)

    if st.session_state.analysis_results is None:
        st.warning("‚ö†Ô∏è Vui l√≤ng ch·∫°y ph√¢n t√≠ch tr∆∞·ªõc!")
        st.stop()

    results = st.session_state.analysis_results
    result_type = results['type']

    # Hi·ªÉn th·ªã theo lo·∫°i ph√¢n t√≠ch
    if result_type == 'unmixing':
        st.write("### K·∫øt qu·∫£ Spectral Unmixing")

        endmembers = results['endmembers']
        abundance_maps = results['abundance_maps']
        data = results['data']

        # Plot endmembers
        st.write("#### üî¨ Endmembers")
        fig1, ax1 = plt.subplots(figsize=(12, 6))

        if hasattr(data, 'spectral_axis'):
            rp.plot.spectra(endmembers, wavenumber_axis=data.spectral_axis, ax=ax1, plot_type='single stacked')
        else:
            rp.plot.spectra(endmembers, ax=ax1, plot_type='single stacked')

        ax1.set_title("Endmember Spectra")
        st.pyplot(fig1)
        plt.close()

        # Plot abundance maps
        st.write("#### üó∫Ô∏è Abundance Maps")

        try:
            # N·∫øu l√† volumetric data, l·∫•y m·ªôt layer
            if len(abundance_maps[0].shape) == 3:
                layer_idx = st.slider("Ch·ªçn layer:", 0, abundance_maps[0].shape[2]-1, abundance_maps[0].shape[2]//2)

                fig2, axes = plt.subplots(1, len(abundance_maps), figsize=(4*len(abundance_maps), 4))
                if len(abundance_maps) == 1:
                    axes = [axes]

                for i, (amap, ax) in enumerate(zip(abundance_maps, axes)):
                    im = ax.imshow(amap[:, :, layer_idx], cmap='viridis')
                    ax.set_title(f"Endmember {i+1}")
                    plt.colorbar(im, ax=ax)

                st.pyplot(fig2)
                plt.close()

            else:
                # 2D data
                fig2, axes = plt.subplots(1, len(abundance_maps), figsize=(4*len(abundance_maps), 4))
                if len(abundance_maps) == 1:
                    axes = [axes]

                for i, (amap, ax) in enumerate(zip(abundance_maps, axes)):
                    im = ax.imshow(amap, cmap='viridis')
                    ax.set_title(f"Endmember {i+1}")
                    plt.colorbar(im, ax=ax)

                st.pyplot(fig2)
                plt.close()

        except Exception as e:
            st.warning(f"Kh√¥ng th·ªÉ hi·ªÉn th·ªã abundance maps: {str(e)}")

    elif result_type == 'peaks':
        st.write("### K·∫øt qu·∫£ Peak Detection")

        spectrum = results['spectrum']
        peaks = results['peaks']

        fig, ax = plt.subplots(figsize=(12, 6))

        # Plot spectrum
        if hasattr(spectrum, 'spectral_axis'):
            x_axis = spectrum.spectral_axis
            y_data = spectrum.spectral_data
        else:
            x_axis = np.arange(len(spectrum))
            y_data = spectrum

        ax.plot(x_axis, y_data, 'b-', linewidth=1.5, label='Spectrum')
        ax.plot(x_axis[peaks], y_data[peaks], 'ro', markersize=8, label='Peaks')

        # ƒê√°nh d·∫•u peaks
        for peak in peaks:
            ax.axvline(x_axis[peak], color='r', linestyle='--', alpha=0.3)
            ax.text(x_axis[peak], y_data[peak], f'{x_axis[peak]:.0f}',
                   rotation=45, ha='right', va='bottom', fontsize=8)

        ax.set_xlabel('Wavenumber (cm‚Åª¬π)')
        ax.set_ylabel('Intensity')
        ax.set_title(f'Peak Detection - {len(peaks)} peaks found')
        ax.legend()
        ax.grid(True, alpha=0.3)

        st.pyplot(fig)
        plt.close()

        # B·∫£ng th√¥ng tin peaks
        st.write("#### üìã Danh s√°ch Peaks")
        peak_data = {
            'Peak #': range(1, len(peaks)+1),
            'Position (index)': peaks,
            'Wavenumber (cm‚Åª¬π)': [f"{x_axis[p]:.2f}" for p in peaks],
            'Intensity': [f"{y_data[p]:.4f}" for p in peaks]
        }

        import pandas as pd
        df = pd.DataFrame(peak_data)
        st.dataframe(df, use_container_width=True)

    elif result_type == 'pca':
        st.write("### K·∫øt qu·∫£ PCA")

        scores = results['scores']
        loadings = results['loadings']
        explained_variance = results['explained_variance']

        col1, col2 = st.columns(2)

        with col1:
            # Scree plot
            st.write("#### üìä Explained Variance")
            fig1, ax1 = plt.subplots(figsize=(6, 4))
            ax1.bar(range(1, len(explained_variance)+1), explained_variance * 100)
            ax1.set_xlabel('Principal Component')
            ax1.set_ylabel('Explained Variance (%)')
            ax1.set_title('Scree Plot')
            st.pyplot(fig1)
            plt.close()

        with col2:
            # Score plot
            st.write("#### üéØ Score Plot (PC1 vs PC2)")
            fig2, ax2 = plt.subplots(figsize=(6, 4))
            ax2.scatter(scores[:, 0], scores[:, 1], alpha=0.6)
            ax2.set_xlabel(f'PC1 ({explained_variance[0]*100:.1f}%)')
            ax2.set_ylabel(f'PC2 ({explained_variance[1]*100:.1f}%)')
            ax2.set_title('PCA Score Plot')
            ax2.grid(True, alpha=0.3)
            st.pyplot(fig2)
            plt.close()

        # Loading plot
        st.write("#### üìà Loading Plots")
        fig3, axes = plt.subplots(1, min(3, len(loadings)), figsize=(12, 4))
        if len(loadings) == 1:
            axes = [axes]

        for i, ax in enumerate(axes[:len(loadings)]):
            ax.plot(loadings[i])
            ax.set_title(f'PC{i+1} Loading')
            ax.set_xlabel('Wavenumber index')
            ax.set_ylabel('Loading')
            ax.grid(True, alpha=0.3)

        plt.tight_layout()
        st.pyplot(fig3)
        plt.close()

# Footer
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: gray;'>
    <p>RamanSPy GUI v1.0 | ƒê∆∞·ª£c x√¢y d·ª±ng v·ªõi Streamlit</p>
    <p>T√†i li·ªáu: <a href='https://ramanspy.readthedocs.io'>ramanspy.readthedocs.io</a></p>
</div>
""", unsafe_allow_html=True)
